# 线性模型与感知机基础

## 1. 线性神经网络用于回归 (Linear Neural Networks for Regression)

### 1.1 什么是回归问题？

想象一下，你正在预测一个连续的数值。比如，根据房屋的面积、地段和房间数量来预测它的价格；或者根据一个人的身高来预测他的体重。这类问题，目标是预测一个具体的数值，而不是一个类别，我们就称之为**回归问题**。

### 1.2 最简单的"模型"：线性回归

在回归问题中，最简单、最直观的模型就是**线性回归**。它假设输入特征和输出之间存在一种线性的关系。你可以把它想象成在数据点之间画一条最能代表它们趋势的直线（或者在更高维度是一个平面）。

**举个例子：**

假设我们想预测一个城市中房屋的价格。我们收集了一些数据，比如房屋的面积（输入特征 $x$）和对应的价格（输出 $y$）。

如果只有一个输入特征，线性回归模型可以表示为：

$$ \text{价格} = \text{权重} \times \text{面积} + \text{偏置} $$

用数学符号表示就是：

$$ y = wx + b $$

*   $y$：我们想要预测的输出（比如房屋价格）。
*   $x$：输入特征（比如房屋面积）。
*   $w$：权重（weight），它决定了特征 $x$ 对输出 $y$ 影响的大小和方向，可以理解为"每平米的价格"。
*   $b$：偏置（bias），它是一个常数，可以理解为"基础价格"或者当所有输入特征都为0时的基准值。它让这条直线可以在Y轴上上下移动。

如果有多个输入特征（比如房屋面积 $x_1$、地段 $x_2$、房间数量 $x_3$），模型就会变成：

$$ y = w_1x_1 + w_2x_2 + w_3x_3 + b $$

### 1.3 损失函数：均方误差 (Mean Squared Error, MSE)

模型预测出来的价格和真实的价格肯定有差距。我们怎么衡量这个差距有多大呢？这就需要**损失函数**。

对于回归问题，最常用的损失函数之一是**均方误差 (MSE)**。它的计算方法是：把每个预测值和真实值之间的差的平方加起来，然后取平均。

$$ MSE = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2 $$

*   $y_i$：第 $i$ 个样本的真实价格。
*   $\hat{y}_i$：第 $i$ 个样本的模型预测价格。
*   $N$：样本的总数量。

**为什么要平方？**

*   **惩罚大误差：** 平方会使得大的误差受到更大的惩罚，让模型更关注那些预测偏离较大的样本。
*   **保证正数：** 无论预测值比真实值大还是小，平方后都变成正数，方便累加。

我们的目标就是找到合适的 $w$ 和 $b$，让这个MSE损失函数的值尽可能小，这意味着模型的预测越接近真实值。

### 1.4 学习过程：如何调整 $w$ 和 $b$

既然我们的目标是让MSE最小，那么模型就需要学习如何调整 $w$ 和 $b$。在后续的章节中，我们会详细介绍**梯度下降**这种强大的算法，它就像一个寻路者，告诉我们沿着哪个方向调整 $w$ 和 $b$ 才能让损失函数下降最快。

现在你只需要知道，模型会通过不断地"试错"和"修正"，逐渐找到最合适的 $w$ 和 $b$，使得那条（或那个）直线（或平面）能够最好地拟合数据，从而准确地预测房屋价格。

## 2. 线性神经网络用于分类 (Linear Neural Networks for Classification)

### 2.1 什么是分类问题？

与回归预测连续数值不同，**分类问题**的目标是预测一个离散的类别标签。比如，判断一张图片是"猫"还是"狗"；判断一封邮件是"垃圾邮件"还是"非垃圾邮件"；或者判断一个病人是否患有某种疾病。

### 2.2 二分类问题与决策边界

最简单的分类问题是**二分类**，即只有两个类别。我们可以用线性模型来尝试解决二分类问题。

**举个例子：**

假设我们要根据水果的甜度（特征 $x_1$）和大小（特征 $x_2$）来判断它是"苹果"还是"橘子"。

在线性分类中，模型会尝试找到一条直线（如果只有两个特征，就是一条线；如果有更多特征，就是一个超平面），将不同类别的样本分隔开。这条分隔线就被称为**决策边界**。

在决策边界的一侧是"苹果"，另一侧是"橘子"。模型就是通过计算样本在哪一侧来决定它的分类。

### 2.3 激活函数：Sigmoid

线性模型的输出 $y = w_1x_1 + w_2x_2 + ... + b$ 可以是任意的实数。但是，在分类问题中，我们通常希望得到一个介于0到1之间的概率值，表示某个类别被选中的可能性。这时，我们就需要引入一个特殊的函数——**激活函数**。

在二分类问题中，常用的激活函数是 **Sigmoid 函数**（也叫 S 型曲线函数）。

$$ \sigma(z) = \frac{1}{1 + e^{-z}} $$

*   $z$：是线性模型的输出 ($w_1x_1 + w_2x_2 + ... + b$)。
*   $\sigma(z)$：Sigmoid 函数的输出，它的值域在 (0, 1) 之间。

**Sigmoid 函数的特点：**

*   它能把任意实数映射到 (0, 1) 区间，非常适合表示概率。
*   当 $z$ 很大时，$\sigma(z)$ 接近 1；当 $z$ 很小时，$\sigma(z)$ 接近 0。
*   当 $z=0$ 时，$\sigma(0) = 0.5$。

**举例：**

如果模型输出 $z=2.5$，经过Sigmoid函数后，结果会接近 0.92，表示这个样本属于某个类别的概率是92%。

### 2.4 损失函数：二元交叉熵 (Binary Cross-Entropy)

对于分类问题，尤其是在输出是概率值时，均方误差 (MSE) 并不是一个好的损失函数。我们更常用的是**交叉熵损失**。

在二分类问题中，我们使用**二元交叉熵 (Binary Cross-Entropy, BCE)**。

假设真实标签 $y$ 是 0 或 1（例如，0代表"非垃圾邮件"，1代表"垃圾邮件"），模型预测的概率是 $\hat{y}$。那么二元交叉熵的计算公式是：

$$ BCE = - [y \log(\hat{y}) + (1 - y) \log(1 - \hat{y})] $$

**为什么要用交叉熵？**

*   **惩罚准确度低的预测：** 如果真实标签是1，但模型预测的概率 $\hat{y}$ 很低（接近0），那么 $-y \log(\hat{y})$ 这一项就会变得非常大，给模型很大的惩罚。
*   **鼓励高置信度：** 如果模型对正确的类别给出了很高的概率，损失就会很小。

我们的目标仍然是调整模型的权重和偏置，使得这个二元交叉熵损失最小。

### 2.5 多分类问题

在现实世界中，分类问题往往不仅仅是二分类。比如，我们要识别手写数字，那就有10个类别（0到9）；识别图像中的物体，可能有上百甚至上千个类别（猫、狗、汽车、飞机等）。这类包含两个以上类别的问题，就称为**多分类问题**。

线性模型同样可以扩展到多分类问题。最常见的方法是为每个类别训练一个独立的线性分类器。

**工作原理：**

想象一下，如果我们要识别猫、狗、鸟三种动物的图片，模型会为每种动物输出一个"得分"：

$$ \text{得分}_{	ext{猫}} = w_{	ext{猫},1}x_1 + w_{	ext{猫},2}x_2 + ... + b_{	ext{猫}} $$
$$ \text{得分}_{	ext{狗}} = w_{	ext{狗},1}x_1 + w_{	ext{狗},2}x_2 + ... + b_{	ext{狗}} $$
$$ \text{得分}_{	ext{鸟}} = w_{	ext{鸟},1}x_1 + w_{	ext{鸟},2}x_2 + ... + b_{	ext{鸟}} $$

每个得分表示输入图片属于该类别的"倾向性"或"原始分数"。这些原始分数可以是任意实数。

### 2.6 激活函数：Softmax

在多分类问题中，我们希望将这些原始分数转换为**概率分布**，即每个类别的概率都在0到1之间，并且所有类别的概率之和为1。这时，我们就会用到一个非常重要的激活函数——**Softmax 函数**。

Softmax 函数的公式如下：

$$ P(y=k | \mathbf{x}) = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}} $$

*   $z_k$：表示第 $k$ 个类别的原始得分（线性模型的输出）。
*   $K$：表示类别的总数量。
*   $e$：自然对数的底数（约等于 2.718）。
*   $P(y=k | \mathbf{x})$：表示在给定输入 $\mathbf{x}$ 的情况下，属于第 $k$ 个类别的概率。

**Softmax 函数的特点：**

*   将一组任意实数（原始得分）转换为一个概率分布。
*   输出值在 (0, 1) 之间。
*   所有输出概率之和为 1。
*   通过指数运算，使得大的得分对应的概率更大，小的得分对应的概率更小，从而突出模型对某个类别的"信心"。

**举例：**

假设模型对一张图片识别猫、狗、鸟的原始得分分别是：
*   猫：$z_{	ext{猫}} = 2.0$
*   狗：$z_{	ext{狗}} = 1.0$
*   鸟：$z_{	ext{鸟}} = -0.5$

应用Softmax函数后，我们会得到：
*   $e^{2.0} \approx 7.389$
*   $e^{1.0} \approx 2.718$
*   $e^{-0.5} \approx 0.607$

总和为 $7.389 + 2.718 + 0.607 \approx 10.714$

*   $P(	ext{猫}) = 7.389 / 10.714 \approx 0.69$
*   $P(	ext{狗}) = 2.718 / 10.714 \approx 0.25$
*   $P(	ext{鸟}) = 0.607 / 10.714 \approx 0.06$

这样我们就得到了这张图片是猫、狗、鸟的概率，分别是69%、25%和6%。模型会选择概率最大的类别作为最终的预测结果（在这个例子中是"猫"）。

### 2.7 损失函数：交叉熵 (Categorical Cross-Entropy)

与二分类问题使用二元交叉熵类似，多分类问题通常使用**交叉熵损失 (Categorical Cross-Entropy)** 来衡量模型预测的概率分布与真实标签之间的差距。

交叉熵损失的计算公式如下：

$$ CrossEntropy = - \sum_{k=1}^{K} y_k \log(\hat{y}_k) $$

*   $y_k$: 真实标签的 one-hot 编码（如果图片是猫，那么猫对应的 $y_k$ 是 1，其他类别是 0）。
*   $\hat{y}_k$: 模型预测的第 $k$ 个类别的概率。
*   $K$: 类别的总数量。

**为什么要用交叉熵？**

*   它能有效地惩罚那些模型对正确类别预测概率过低的错误，鼓励模型对正确的类别给出高置信度的预测。
*   当真实标签是某个类别时，只有该类别对应的 $\hat{y}_k$ 会对损失函数产生贡献，如果 $\hat{y}_k$ 越接近1，损失越小；越接近0，损失越大。

我们的目标就是调整模型的权重和偏置，使得这个交叉熵损失最小。

## 3. 什么是神经元？

### 3.1 类比：人脑神经元

想象一下我们人脑中的神经元，它们是构成大脑的基本单位，负责接收、处理和传递信息。当一个神经元接收到足够的"刺激"时，它就会被"激活"，然后将信号传递给下一个神经元。深度学习中的"神经元"就是对这种生物神经元的一种数学抽象和模拟。

**用人话说：**

你可以把一个神经元想象成一个**小小的决策单元**。它接收一些信息（输入），对这些信息进行一番"思考"（处理），然后根据思考的结果给出一个"决定"（输出）。

### 3.2 神经元的数学模型

一个人工神经元（也常称为"感知机"）通常包含以下几个核心部分：

1.  **输入 (Inputs):** 神经元接收的数据或信息。这些输入通常是来自其他神经元或原始数据（比如一张图片的像素值、一个词的特征）。我们用 $x_1, x_2, ..., x_n$ 来表示这些输入。

2.  **权重 (Weights):** 每个输入都有一个对应的权重 $w_1, w_2, ..., w_n$。权重决定了每个输入的重要性或者对神经元输出的影响程度。想象一下，你听取朋友们对一件事的意见，有些朋友的话你更信任，所以你给他们的话分配了更高的"权重"。

3.  **偏置 (Bias):** 偏置 $b$ 是一个额外的常数项。它允许神经元在没有接收任何输入时也能有一个基础的"活跃度"，或者说它控制了神经元被激活的"门槛"。

4.  **加权和 (Weighted Sum):** 神经元首先会将所有输入乘以它们各自的权重，然后把这些乘积加起来，最后再加上偏置。这就像在计算一个"总分"：

    $$ z = w_1x_1 + w_2x_2 + ... + w_nx_n + b $$

    也可以用更简洁的向量点积形式表示：

    $$ z = \mathbf{w} \cdot \mathbf{x} + b $$

    其中 $\mathbf{w}$ 是权重向量，$\mathbf{x}$ 是输入向量。

5.  **激活函数 (Activation Function):** 这是神经元的"灵魂"部分。在计算出加权和 $z$ 之后，神经元会将 $z$ 传递给一个非线性的函数，这个函数就是激活函数。它决定了神经元最终是否被"激活"以及激活的程度。它的作用是将这个"总分"转换成神经元的最终输出。

    $$ \text{输出} = f(z) = f(\mathbf{w} \cdot \mathbf{x} + b) $$

    其中 $f$ 就是激活函数。

**举个例子：下雨，我要不要带伞？**

我们用一个神经元来模拟这个决策过程：

*   **输入 $x_1$：** "天气预报说下雨了吗？" (是=1，否=0)
*   **输入 $x_2$：** "我今天出门时间长吗？" (长=1，短=0)

*   **权重 $w_1$：** 假设"天气预报"对你来说非常重要，权重设为 5。
*   **权重 $w_2$：** 假设"出门时间"相对不那么重要，权重设为 2。
*   **偏置 $b$：** 假设你是一个非常怕麻烦的人，除非特别有必要，否则不想带伞，偏置设为 -3（负的偏置意味着需要更高的输入加权和才能激活）。

*   **激活函数 $f$：** 我们用一个简单的阶跃函数：如果输出大于0，就带伞（1）；否则就不带伞（0）。

**情况一：天气预报说下雨 (x1=1)，出门时间长 (x2=1)**

1.  **加权和 $z$：** $z = (5 \times 1) + (2 \times 1) + (-3) = 5 + 2 - 3 = 4$
2.  **激活：** $f(4) = 1$ (大于0，带伞)

**情况二：天气预报说不下雨 (x1=0)，出门时间短 (x2=0)**

1.  **加权和 $z$：** $z = (5 \times 0) + (2 \times 0) + (-3) = 0 + 0 - 3 = -3$
2.  **激活：** $f(-3) = 0$ (小于0，不带伞)

通过调整权重和偏置，这个神经元就能模拟不同的决策逻辑。这就是神经元最基础的工作方式。

## 4. 感知机登场：最简单的"智能"模型

**感知机 (Perceptron)** 是人工神经网络的早期模型，由Frank Rosenblatt在1957年提出。它本质上就是一个**单层的人工神经元**，能够进行二分类（将数据分成两类）。

### 4.1 感知机的工作原理

感知机的工作方式与我们前面介绍的神经元完全一致：

1.  **接收输入：** 接收多个输入特征 $x_1, x_2, ..., x_n$。
2.  **加权求和与偏置：** 对输入进行加权求和并加上偏置 $z = \mathbf{w} \cdot \mathbf{x} + b$。
3.  **激活函数：** 将加权和 $z$ 通过一个**阶跃函数**（或者符号函数）来决定最终的输出。对于感知机，这个阶跃函数通常是：
    *   如果 $z > 0$，输出 1
    *   如果 $z \le 0$，输出 0 (或者 -1)

**类比：画条线把东西分开**

想象你有一堆红色和蓝色的球混在一起。感知机要做的就是找到一条直线（在二维空间）或者一个平面（在三维空间），能把红球和蓝球完美地分开。

*   **如果球在线的这一边，它就是红球。**
*   **如果球在线的那一边，它就是蓝球。**

这条线就是感知机的**决策边界**。感知机只能找到直线（或平面）来分隔数据，因此它是一个**线性分类器**。

### 4.2 感知机的局限性：异或问题

感知机虽然简单，但它有一个致命的弱点：**它只能解决线性可分的问题。**

什么叫线性可分？就是可以用一条直线（或一个平面）把不同类别的数据完全分开。比如上面说的红球和蓝球，如果它们是分布在直线的两边，那感知机就能搞定。

但是，有些问题是**非线性可分**的。最有名的例子就是**"异或" (XOR) 问题**。异或逻辑是这样的：

*   输入 (0, 0) -> 输出 0
*   输入 (0, 1) -> 输出 1
*   输入 (1, 0) -> 输出 1
*   输入 (1, 1) -> 输出 0

如果你在坐标轴上画出这四个点，你会发现，无论你怎么画一条直线，都无法把属于类别1的点（(0,1) 和 (1,0)）和属于类别0的点（(0,0) 和 (1,1)）完全分开。

**这意味着：** 单个感知机无法解决异或问题。这个局限性在当时一度让人们对神经网络失去了兴趣。但这也引出了后续章节中更复杂的神经网络——**多层感知机**的必要性，因为多层网络可以通过非线性的组合来解决这类问题。

## 5. 激活函数：神经元的"兴奋度"开关

前面我们提到，神经元在计算出加权和 $z$ 之后，会通过一个**激活函数 (Activation Function)** 来产生最终的输出。激活函数就像神经元的"兴奋度"开关，它决定了神经元被激活的程度，并引入了非线性。

### 5.1 为什么需要激活函数？

**核心目的：引入非线性！**

如果没有激活函数（或者只使用线性激活函数，比如 $f(x)=x$），无论你叠加多少层神经网络，整个网络最终都只会是一个**线性模型**。这意味着它仍然只能解决线性可分的问题，就像前面提到的感知机一样，无法处理复杂的非线性关系。

**举个例子：**

如果你把两个线性函数 $f_1(x) = ax+b$ 和 $f_2(y) = cy+d$ 组合起来，比如 $f_2(f_1(x)) = c(ax+b)+d = acx + cb + d$，结果仍然是一个线性函数。深度学习之所以强大，就是因为它能够学习并表示**非线性**的复杂模式，而这正是激活函数带来的贡献。

### 5.2 常见的激活函数

#### 5.2.1 Sigmoid 函数 (S 型曲线)

前面在"线性神经网络用于分类"中已经介绍了Sigmoid函数，它是早期神经网络中非常流行的一种激活函数。

$$ \sigma(z) = \frac{1}{1 + e^{-z}} $$

**图像大致形状描述：**

S 型曲线，输出值在 (0, 1) 之间。在输入值非常大或非常小时，函数的梯度（斜率）会变得非常小，接近于0。这就是著名的**梯度消失问题**。

**优点：**

*   将输出压缩到 (0, 1) 之间，可以解释为概率。
*   平滑、可导，方便进行梯度计算。

**缺点：**

*   **梯度消失：** 当输入非常大或非常小时，梯度接近0，导致网络在反向传播时很难更新靠近输入层的权重，学习速度变慢甚至停滞。这使得深层网络难以训练。
*   **输出不以0为中心：** 这可能会导致梯度更新时的"锯齿"现象，影响训练效率。

#### 5.2.2 ReLU 函数 (修正线性单元 - Rectified Linear Unit)

ReLU 函数是目前在深度学习中最常用的激活函数之一，尤其是在卷积神经网络中。

$$ ReLU(z) = \max(0, z) $$

**图像大致形状描述：**

当输入 $z > 0$ 时，输出就是 $z$；当 $z \le 0$ 时，输出是 0。它就像一个"截断"的线性函数。

```
^ Output
|
|      /
|     /
|    /
|   /
|  /
| /
+-----------> Input
0
```

**优点：**

*   **解决了梯度消失问题：** 当 $z > 0$ 时，梯度恒为 1，有效避免了梯度消失。这使得网络可以训练得更深。
*   **计算效率高：** 只需要进行简单的阈值判断，计算速度比Sigmoid和Tanh快很多。
*   **稀疏激活：** 当 $z \le 0$ 时，输出为0，这意味着一部分神经元处于非激活状态，这有助于创建稀疏网络，提高计算效率和特征选择能力。

**缺点：**

*   **"死亡ReLU"问题：** 当输入 $z$ 永远小于等于 0 时，该神经元就不会被激活，梯度永远为 0，导致该神经元及其连接的权重无法更新，变得"死亡"。
*   **输出不以0为中心：** 和Sigmoid一样，输出不以0为中心。

#### 5.2.3 其他激活函数（简单提及）

*   **Tanh 函数 (双曲正切函数):** 形状类似Sigmoid，但输出范围在 (-1, 1) 之间，输出以0为中心，比Sigmoid表现更好，但仍有梯度消失问题。
*   **Leaky ReLU、PReLU、ELU 等：** 针对ReLU的"死亡ReLU"问题进行改进，当输入小于0时，允许一个很小的非零梯度。

### 5.3 为什么不直接使用阶跃函数？

虽然我们在感知机的例子中使用了阶跃函数，但在实际深度学习中，我们很少直接使用它，原因在于：

*   **不可导：** 阶跃函数在 $z=0$ 处不连续，在其他地方导数为0。这意味着在反向传播过程中，我们无法计算梯度，也就无法通过梯度下降来更新权重。

所以，像Sigmoid和ReLU这样平滑或分段平滑的函数，因为它们处处可导（或几乎处处可导），才更适合用于深度学习模型的训练。

## 6. 感知机的训练：如何让它"学习"

感知机能够学习的核心在于它的**训练算法**。这里的"学习"指的是通过调整神经元的权重 $w$ 和偏置 $b$，使其能够正确地对新的输入进行分类。

### 6.1 损失函数：衡量"犯错"的程度

在训练过程中，我们需要一个指标来衡量模型预测的"好坏"，也就是模型"犯错"的程度。这个指标就是**损失函数 (Loss Function)**。

对于感知机（二分类问题），一个简单的损失概念可以是：**如果预测错误，则产生损失；如果预测正确，则损失为0。** 我们希望通过训练让总的损失最小。

### 6.2 权重更新规则：知错就改

当感知机对一个样本做出错误预测时，我们会根据错误的大小来调整其权重和偏置。这个调整的规则是感知机学习算法的关键。

假设我们有一个样本，真实标签是 $y_{true}$，模型预测的输出是 $y_{pred}$。

**如果预测错误：**

*   **权重更新：** $w_{new} = w_{old} + \alpha \times (y_{true} - y_{pred}) \times x$
*   **偏置更新：** $b_{new} = b_{old} + \alpha \times (y_{true} - y_{pred})$

*   $\alpha$ (alpha)：**学习率 (Learning Rate)**，这是一个很小的正数（比如 0.01 或 0.1）。它决定了每次调整权重和偏置的步长。学习率太小，训练会很慢；学习率太大，可能会导致模型不稳定，甚至错过最佳点。
*   $(y_{true} - y_{pred})$：这表示了预测的误差。
    *   如果 $y_{true}=1$ 但 $y_{pred}=0$ (本应是1，却预测成0)，误差是 $+1$，权重会增加，使得下次更容易预测成1。
    *   如果 $y_{true}=0$ 但 $y_{pred}=1$ (本应是0，却预测成1)，误差是 $-1$，权重会减小，使得下次更容易预测成0。
*   $x$：当前输入的特征值。这表明特征值越大，其对应的权重调整的幅度也可能越大。

**用人话说：**

想象你是一个射击运动员，目标是靶心（真实标签）。

*   **如果你射偏了（预测错误）：** 你的教练（算法）会告诉你偏了多少，并根据你偏离的方向和程度（误差），让你稍微调整一下枪口（权重和偏置）。
*   **学习率：** 就是你每次调整枪口的幅度。幅度大了可能一下就过头，幅度小了可能要调很久。

### 6.3 迭代学习：熟能生巧

感知机通过**迭代学习**的方式来提高性能。它会一遍又一遍地遍历训练数据集中的所有样本（这一个完整的遍历过程叫做一个**"周期" Epoch**），每次遇到预测错误的样本时，就按照上面的规则调整权重和偏置。

随着训练周期的增加，感知机会不断地从错误中学习，逐渐找到一套能够正确分类大多数甚至所有训练样本的权重和偏置。这个过程就叫做**收敛**。

### 6.4 权重衰减 (Weight Decay)

权重衰减（Weight Decay），也称为 L2 正则化，是一种常用的正则化技术，用于防止模型过拟合。它通过在损失函数中添加一个惩罚项，使得模型的权重趋向于较小的值。

其在损失函数中的体现为：

$$L_{total} = L_{original} + \frac{1}{2} \lambda \sum_{i} w_i^2$$

其中：
- $L_{total}$ 是包含权重衰减的总损失函数。
- $L_{original}$ 是原始的损失函数（例如，均方误差或交叉熵损失）。
- $\lambda$ (lambda) 是权重衰减系数，一个超参数，用于控制正则化强度。$\lambda$ 越大，权重衰减的惩罚越大，模型权重会更小。
- $\sum_{i} w_i^2$ 是模型所有权重的平方和（L2 范数）。

#### 6.4.1 权重衰减的梯度推导

对于权重衰减项，其对权重 $w_i$ 的梯度为：

$$\frac{\partial}{\partial w_i} \left(\frac{1}{2} \lambda \sum_{j} w_j^2\right) = \lambda w_i$$

因此，包含权重衰减的总梯度为：

$$\frac{\partial L_{total}}{\partial w_i} = \frac{\partial L_{original}}{\partial w_i} + \lambda w_i$$

权重更新规则变为：

$$w_i^{(new)} = w_i^{(old)} - \eta \left(\frac{\partial L_{original}}{\partial w_i} + \lambda w_i^{(old)}\right)$$

这可以重写为：

$$w_i^{(new)} = w_i^{(old)}(1 - \eta \lambda) - \eta \frac{\partial L_{original}}{\partial w_i}$$

其中 $(1 - \eta \lambda)$ 就是权重衰减因子。

#### 6.4.2 数值计算例子

**假设场景：** 我们有一个简单的线性回归模型：$y = w_1x_1 + w_2x_2 + b$

**给定参数：**
- 当前权重：$w_1 = 2.5$, $w_2 = -1.8$, $b = 0.3$
- 学习率：$\eta = 0.01$
- 权重衰减系数：$\lambda = 0.1$
- 原始梯度（从数据计算得出）：$\frac{\partial L_{original}}{\partial w_1} = 0.5$, $\frac{\partial L_{original}}{\partial w_2} = -0.3$

**步骤1：计算权重衰减项的梯度**

$$\frac{\partial}{\partial w_1}\left(\frac{1}{2}\lambda(w_1^2 + w_2^2)\right) = \lambda w_1 = 0.1 \times 2.5 = 0.25$$

$$\frac{\partial}{\partial w_2}\left(\frac{1}{2}\lambda(w_1^2 + w_2^2)\right) = \lambda w_2 = 0.1 \times (-1.8) = -0.18$$

**步骤2：计算总梯度**

$$\frac{\partial L_{total}}{\partial w_1} = 0.5 + 0.25 = 0.75$$

$$\frac{\partial L_{total}}{\partial w_2} = -0.3 + (-0.18) = -0.48$$

**步骤3：更新权重**

$$w_1^{(new)} = w_1^{(old)} - \eta \times \frac{\partial L_{total}}{\partial w_1} = 2.5 - 0.01 \times 0.75 = 2.5 - 0.0075 = 2.4925$$

$$w_2^{(new)} = w_2^{(old)} - \eta \times \frac{\partial L_{total}}{\partial w_2} = -1.8 - 0.01 \times (-0.48) = -1.8 + 0.0048 = -1.7952$$

**验证使用衰减因子的计算方法：**

权重衰减因子：$1 - \eta \lambda = 1 - 0.01 \times 0.1 = 1 - 0.001 = 0.999$

$$w_1^{(new)} = w_1^{(old)} \times 0.999 - \eta \times \frac{\partial L_{original}}{\partial w_1}$$
$$= 2.5 \times 0.999 - 0.01 \times 0.5 = 2.4975 - 0.005 = 2.4925$$

验证结果：✓

$$w_2^{(new)} = w_2^{(old)} \times 0.999 - \eta \times \frac{\partial L_{original}}{\partial w_2}$$
$$= -1.8 \times 0.999 - 0.01 \times (-0.3) = -1.7982 + 0.003 = -1.7952$$

验证结果：✓

#### 6.4.3 权重衰减的效果分析

从上面的计算可以看到：

1. **权重缩小效应：** 无论原始梯度如何，权重都会乘以小于1的衰减因子 $(1 - \eta \lambda) = 0.999$，使权重整体趋向于减小。

2. **大权重惩罚更重：** 权重衰减的梯度 $\lambda w_i$ 与权重成正比，权重越大，受到的"推向零"的力量越强。在例子中：
   - $w_1 = 2.5$（较大）受到的衰减梯度为 $0.25$
   - $w_2 = -1.8$（绝对值较小）受到的衰减梯度为 $-0.18$（绝对值较小）

3. **防止过拟合：** 通过限制权重的大小，模型变得更加"简单"，减少了对训练数据的过度依赖。

**长期效果模拟：**

假设我们连续进行10次更新，只考虑权重衰减的影响（假设原始梯度为0）：

$$w_1^{(after\ 10\ steps)} = 2.5 \times (0.999)^{10} = 2.5 \times 0.99004 = 2.4751$$

可以看到，即使没有来自数据的梯度，权重也会逐渐衰减，这正是权重衰减防止过拟合的机制。

在梯度下降更新规则中，权重衰减等效于在每次迭代时，将权重乘以一个小于1的因子（即 $1 - \eta \lambda$），其中 $\eta$ 是学习率。这使得权重在每次更新后都会衰减一部分，从而限制了模型的复杂度。 
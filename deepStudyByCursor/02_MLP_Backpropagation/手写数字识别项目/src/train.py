"""
Training Script for Handwritten Digit Recognition
æ‰‹å†™æ•°å­—è¯†åˆ«è®­ç»ƒè„šæœ¬

This script trains an MLP from scratch on the MNIST dataset.
æœ¬è„šæœ¬åœ¨MNISTæ•°æ®é›†ä¸Šä»é›¶è®­ç»ƒMLPã€‚
"""

import os
import sys
import argparse
import time
import numpy as np
import matplotlib.pyplot as plt
from data_loader import MNISTDataLoader
from mlp_scratch import MLPClassifier

def create_results_directory():
    """
    Create results directory structure
    åˆ›å»ºç»“æœç›®å½•ç»“æ„
    """
    results_dir = '../results'
    subdirs = ['models', 'plots', 'logs']
    
    for subdir in [results_dir] + [os.path.join(results_dir, sub) for sub in subdirs]:
        os.makedirs(subdir, exist_ok=True)
    
    return results_dir

def train_mnist_classifier(config):
    """
    Train MLP classifier on MNIST dataset
    åœ¨MNISTæ•°æ®é›†ä¸Šè®­ç»ƒMLPåˆ†ç±»å™¨
    
    Args:
        config: Configuration dictionary with training parameters
    """
    print("ğŸš€ Starting MNIST Handwritten Digit Recognition Training")
    print("ğŸš€ å¼€å§‹MNISTæ‰‹å†™æ•°å­—è¯†åˆ«è®­ç»ƒ")
    print("=" * 70)
    
    # Create results directory (åˆ›å»ºç»“æœç›®å½•)
    results_dir = create_results_directory()
    
    # Initialize data loader (åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨)
    print("ğŸ“ Loading MNIST dataset... (æ­£åœ¨åŠ è½½MNISTæ•°æ®é›†...)")
    data_loader = MNISTDataLoader(
        data_dir='../data',
        batch_size=config['batch_size'],
        validation_split=config['validation_split']
    )
    
    # Load preprocessed data (åŠ è½½é¢„å¤„ç†çš„æ•°æ®)
    data = data_loader.load_numpy_data()
    X_train, y_train = data['X_train'], data['y_train']
    X_val, y_val = data['X_val'], data['y_val']
    X_test, y_test = data['X_test'], data['y_test']
    
    print("âœ… Data loaded successfully! (æ•°æ®åŠ è½½æˆåŠŸï¼)")
    print(f"Training set: {X_train.shape[0]} samples (è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬)")
    print(f"Validation set: {X_val.shape[0]} samples (éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬)")
    print(f"Test set: {X_test.shape[0]} samples (æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬)")
    print(f"Input features: {X_train.shape[1]} (è¾“å…¥ç‰¹å¾: {X_train.shape[1]})")
    print(f"Number of classes: {len(np.unique(y_train))} (ç±»åˆ«æ•°: {len(np.unique(y_train))})")
    print("-" * 50)
    
    # Create model (åˆ›å»ºæ¨¡å‹)
    print("ğŸ§  Creating MLP model... (æ­£åœ¨åˆ›å»ºMLPæ¨¡å‹...)")
    model = MLPClassifier(
        layer_sizes=config['layer_sizes'],
        activations=config['activations']
    )
    
    print(f"Model architecture: {config['layer_sizes']}")
    print(f"æ¨¡å‹æ¶æ„: {config['layer_sizes']}")
    print(f"Activation functions: {config['activations']}")
    print(f"æ¿€æ´»å‡½æ•°: {config['activations']}")
    print("-" * 50)
    
    # Train model (è®­ç»ƒæ¨¡å‹)
    print("ğŸ‹ï¸ Starting training... (å¼€å§‹è®­ç»ƒ...)")
    start_time = time.time()
    
    history = model.fit(
        X_train=X_train,
        y_train=y_train,
        X_val=X_val,
        y_val=y_val,
        epochs=config['epochs'],
        batch_size=config['batch_size'],
        learning_rate=config['learning_rate'],
        verbose=True
    )
    
    training_time = time.time() - start_time
    print(f"â±ï¸ Training completed in {training_time:.2f} seconds")
    print(f"â±ï¸ è®­ç»ƒåœ¨ {training_time:.2f} ç§’å†…å®Œæˆ")
    print("-" * 50)
    
    # Evaluate model (è¯„ä¼°æ¨¡å‹)
    print("ğŸ“Š Evaluating model... (æ­£åœ¨è¯„ä¼°æ¨¡å‹...)")
    
    train_accuracy = model.compute_accuracy(X_train, y_train)
    val_accuracy = model.compute_accuracy(X_val, y_val)
    test_accuracy = model.compute_accuracy(X_test, y_test)
    
    # Compute final losses (è®¡ç®—æœ€ç»ˆæŸå¤±)
    train_loss = model.compute_loss(X_train, model._to_onehot(y_train))
    val_loss = model.compute_loss(X_val, model._to_onehot(y_val))
    test_loss = model.compute_loss(X_test, model._to_onehot(y_test))
    
    print("ğŸ“ˆ Final Results (æœ€ç»ˆç»“æœ):")
    print(f"  Training   - Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)")
    print(f"  Validation - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)")
    print(f"  Test       - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
    print("-" * 50)
    
    # Save model (ä¿å­˜æ¨¡å‹)
    model_path = os.path.join(results_dir, 'models', 'mnist_mlp_scratch.pkl')
    model.save_model(model_path)
    
    # Plot and save training history (ç»˜åˆ¶å¹¶ä¿å­˜è®­ç»ƒå†å²)
    plot_path = os.path.join(results_dir, 'plots', 'training_history.png')
    model.plot_training_history(save_path=plot_path)
    
    # Generate detailed analysis (ç”Ÿæˆè¯¦ç»†åˆ†æ)
    generate_analysis_report(model, data, results_dir, config, training_time)
    
    # Visualize predictions (å¯è§†åŒ–é¢„æµ‹)
    visualize_predictions(model, X_test, y_test, results_dir)
    
    return model, history

def generate_analysis_report(model, data, results_dir, config, training_time):
    """
    Generate detailed analysis report
    ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š
    """
    print("ğŸ“ Generating analysis report... (æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...)")
    
    X_train, y_train = data['X_train'], data['y_train']
    X_val, y_val = data['X_val'], data['y_val']
    X_test, y_test = data['X_test'], data['y_test']
    
    # Classification report for each class (æ¯ä¸ªç±»åˆ«çš„åˆ†ç±»æŠ¥å‘Š)
    test_predictions = model.predict(X_test)
    test_probabilities = model.predict_proba(X_test)
    
    # Per-class accuracy (æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡)
    class_accuracies = {}
    for class_idx in range(10):
        mask = y_test == class_idx
        if np.sum(mask) > 0:
            class_acc = np.mean(test_predictions[mask] == class_idx)
            class_accuracies[class_idx] = class_acc
    
    # Generate report text (ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬)
    report_path = os.path.join(results_dir, 'logs', 'training_report.txt')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("MNIST Handwritten Digit Recognition - Training Report\n")
        f.write("MNISTæ‰‹å†™æ•°å­—è¯†åˆ« - è®­ç»ƒæŠ¥å‘Š\n")
        f.write("=" * 60 + "\n\n")
        
        # Configuration (é…ç½®)
        f.write("Configuration (é…ç½®):\n")
        f.write("-" * 30 + "\n")
        f.write(f"Model Architecture: {config['layer_sizes']}\n")
        f.write(f"Activations: {config['activations']}\n")
        f.write(f"Epochs: {config['epochs']}\n")
        f.write(f"Batch Size: {config['batch_size']}\n")
        f.write(f"Learning Rate: {config['learning_rate']}\n")
        f.write(f"Validation Split: {config['validation_split']}\n")
        f.write(f"Training Time: {training_time:.2f} seconds\n\n")
        
        # Dataset Information (æ•°æ®é›†ä¿¡æ¯)
        f.write("Dataset Information (æ•°æ®é›†ä¿¡æ¯):\n")
        f.write("-" * 30 + "\n")
        f.write(f"Training samples: {X_train.shape[0]}\n")
        f.write(f"Validation samples: {X_val.shape[0]}\n")
        f.write(f"Test samples: {X_test.shape[0]}\n")
        f.write(f"Input features: {X_train.shape[1]} (28x28 pixels)\n")
        f.write(f"Number of classes: 10 (digits 0-9)\n\n")
        
        # Final Performance (æœ€ç»ˆæ€§èƒ½)
        train_acc = model.compute_accuracy(X_train, y_train)
        val_acc = model.compute_accuracy(X_val, y_val)
        test_acc = model.compute_accuracy(X_test, y_test)
        
        f.write("Final Performance (æœ€ç»ˆæ€§èƒ½):\n")
        f.write("-" * 30 + "\n")
        f.write(f"Training Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)\n")
        f.write(f"Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\n")
        f.write(f"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\n\n")
        
        # Per-class accuracy (æ¯ä¸ªç±»åˆ«å‡†ç¡®ç‡)
        f.write("Per-Class Accuracy (æ¯ä¸ªç±»åˆ«å‡†ç¡®ç‡):\n")
        f.write("-" * 30 + "\n")
        for class_idx, accuracy in class_accuracies.items():
            f.write(f"Digit {class_idx}: {accuracy:.4f} ({accuracy*100:.2f}%)\n")
        f.write("\n")
        
        # Training Progress (è®­ç»ƒè¿›åº¦)
        f.write("Training Progress (è®­ç»ƒè¿›åº¦):\n")
        f.write("-" * 30 + "\n")
        f.write(f"Best Training Accuracy: {max(model.train_accuracies):.4f}\n")
        f.write(f"Best Validation Accuracy: {max(model.val_accuracies):.4f}\n")
        f.write(f"Final Training Loss: {model.train_losses[-1]:.4f}\n")
        f.write(f"Final Validation Loss: {model.val_losses[-1]:.4f}\n")
    
    print(f"âœ… Analysis report saved to: {report_path}")
    print(f"âœ… åˆ†ææŠ¥å‘Šä¿å­˜åˆ°: {report_path}")

def visualize_predictions(model, X_test, y_test, results_dir):
    """
    Visualize model predictions on test samples
    å¯è§†åŒ–æ¨¡å‹åœ¨æµ‹è¯•æ ·æœ¬ä¸Šçš„é¢„æµ‹
    """
    print("ğŸ¨ Creating prediction visualizations... (æ­£åœ¨åˆ›å»ºé¢„æµ‹å¯è§†åŒ–...)")
    
    # Select random test samples (é€‰æ‹©éšæœºæµ‹è¯•æ ·æœ¬)
    n_samples = 20
    indices = np.random.choice(len(X_test), n_samples, replace=False)
    
    # Make predictions (è¿›è¡Œé¢„æµ‹)
    predictions = model.predict(X_test[indices])
    probabilities = model.predict_proba(X_test[indices])
    true_labels = y_test[indices]
    
    # Create visualization (åˆ›å»ºå¯è§†åŒ–)
    fig, axes = plt.subplots(4, 5, figsize=(15, 12))
    fig.suptitle('Model Predictions on Test Set (æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹)', fontsize=16, y=0.98)
    
    for i, idx in enumerate(indices):
        row, col = i // 5, i % 5
        
        # Reshape image (é‡å¡‘å›¾ç‰‡)
        image = X_test[idx].reshape(28, 28)
        true_label = true_labels[i]
        pred_label = predictions[i]
        confidence = probabilities[i][pred_label]
        
        # Plot image (ç»˜åˆ¶å›¾ç‰‡)
        axes[row, col].imshow(image, cmap='gray')
        
        # Set title with prediction info (è®¾ç½®å¸¦é¢„æµ‹ä¿¡æ¯çš„æ ‡é¢˜)
        color = 'green' if pred_label == true_label else 'red'
        title = f'True: {true_label}, Pred: {pred_label}\nConf: {confidence:.3f}'
        axes[row, col].set_title(title, color=color, fontsize=10)
        axes[row, col].axis('off')
    
    plt.tight_layout()
    
    # Save visualization (ä¿å­˜å¯è§†åŒ–)
    pred_plot_path = os.path.join(results_dir, 'plots', 'predictions_visualization.png')
    plt.savefig(pred_plot_path, dpi=300, bbox_inches='tight')
    plt.show()
    
    # Create confusion matrix visualization (åˆ›å»ºæ··æ·†çŸ©é˜µå¯è§†åŒ–)
    create_confusion_matrix(model, X_test, y_test, results_dir)
    
    print(f"âœ… Prediction visualizations saved to: {pred_plot_path}")
    print(f"âœ… é¢„æµ‹å¯è§†åŒ–ä¿å­˜åˆ°: {pred_plot_path}")

def create_confusion_matrix(model, X_test, y_test, results_dir):
    """
    Create and save confusion matrix
    åˆ›å»ºå¹¶ä¿å­˜æ··æ·†çŸ©é˜µ
    """
    from sklearn.metrics import confusion_matrix
    import seaborn as sns
    
    # Get predictions (è·å–é¢„æµ‹)
    predictions = model.predict(X_test)
    
    # Create confusion matrix (åˆ›å»ºæ··æ·†çŸ©é˜µ)
    cm = confusion_matrix(y_test, predictions)
    
    # Normalize confusion matrix (æ ‡å‡†åŒ–æ··æ·†çŸ©é˜µ)
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    
    # Plot confusion matrix (ç»˜åˆ¶æ··æ·†çŸ©é˜µ)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues',
                xticklabels=range(10), yticklabels=range(10))
    plt.title('Normalized Confusion Matrix (æ ‡å‡†åŒ–æ··æ·†çŸ©é˜µ)')
    plt.xlabel('Predicted Label (é¢„æµ‹æ ‡ç­¾)')
    plt.ylabel('True Label (çœŸå®æ ‡ç­¾)')
    
    # Save confusion matrix (ä¿å­˜æ··æ·†çŸ©é˜µ)
    cm_path = os.path.join(results_dir, 'plots', 'confusion_matrix.png')
    plt.savefig(cm_path, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"âœ… Confusion matrix saved to: {cm_path}")
    print(f"âœ… æ··æ·†çŸ©é˜µä¿å­˜åˆ°: {cm_path}")

def main():
    """
    Main training function
    ä¸»è®­ç»ƒå‡½æ•°
    """
    parser = argparse.ArgumentParser(description='Train MLP for MNIST digit recognition')
    parser.add_argument('--epochs', type=int, default=50, help='Number of training epochs')
    parser.add_argument('--batch_size', type=int, default=64, help='Batch size')
    parser.add_argument('--learning_rate', type=float, default=0.01, help='Learning rate')
    parser.add_argument('--hidden_sizes', nargs='+', type=int, default=[128, 64], 
                        help='Hidden layer sizes')
    parser.add_argument('--validation_split', type=float, default=0.1, 
                        help='Validation split ratio')
    
    args = parser.parse_args()
    
    # Configuration (é…ç½®)
    config = {
        'layer_sizes': [784] + args.hidden_sizes + [10],  # Input: 784, Output: 10
        'activations': ['relu'] * len(args.hidden_sizes),
        'epochs': args.epochs,
        'batch_size': args.batch_size,
        'learning_rate': args.learning_rate,
        'validation_split': args.validation_split
    }
    
    # Set random seed for reproducibility (è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡ç°æ€§)
    np.random.seed(42)
    
    try:
        # Train model (è®­ç»ƒæ¨¡å‹)
        model, history = train_mnist_classifier(config)
        
        print("\nğŸ‰ Training completed successfully! (è®­ç»ƒæˆåŠŸå®Œæˆï¼)")
        print("ğŸ‰ Check the results directory for saved models and visualizations.")
        print("ğŸ‰ æŸ¥çœ‹resultsç›®å½•ä¸­ä¿å­˜çš„æ¨¡å‹å’Œå¯è§†åŒ–ç»“æœã€‚")
        
    except Exception as e:
        print(f"âŒ Error during training: {e}")
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        raise

if __name__ == "__main__":
    main() 
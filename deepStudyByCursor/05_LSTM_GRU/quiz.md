# 第五章：长短期记忆网络(LSTM)与门控循环单元(GRU) - 测试题

## 选择题

### 1. LSTM相比传统RNN的主要优势是什么？
A. 计算速度更快  
B. 参数数量更少  
C. 能够处理长期依赖问题  
D. 网络结构更简单  

### 2. LSTM中的"遗忘门"的主要作用是什么？
A. 决定输入哪些信息  
B. 决定遗忘细胞状态中的哪些信息  
C. 决定输出哪些信息  
D. 更新隐藏状态  

### 3. 在LSTM中，细胞状态(Cell State)的作用是什么？
A. 存储短期记忆  
B. 作为最终输出  
C. 传递长期信息的"传送带"  
D. 控制门的开关  

### 4. GRU相比LSTM的主要特点是什么？
A. 参数更多，性能更好  
B. 结构更复杂，门更多  
C. 参数更少，结构更简洁  
D. 只能处理短序列  

### 5. 在处理序列数据时，梯度消失问题主要发生在什么情况下？
A. 序列太短  
B. 学习率太大  
C. 序列太长且使用简单RNN  
D. 批量大小太小  

## 填空题

### 1. LSTM有三个门：______门、______门和______门，分别控制信息的遗忘、输入和输出。

### 2. 在LSTM的前向传播中，细胞状态的更新公式是：C_t = ______*C_{t-1} + ______*候选值

### 3. GRU只有两个门：______门和______门，相比LSTM减少了参数数量。

### 4. LSTM中的Sigmoid函数输出范围是______到______，用于控制信息流的比例。

### 5. 在序列到序列(Seq2Seq)模型中，编码器的最后一个隐藏状态通常作为解码器的______状态。

## 简答题

### 1. 详细解释LSTM的三个门(遗忘门、输入门、输出门)的工作原理和数学公式。

### 2. 比较LSTM和GRU的结构差异，分析各自的优缺点。

### 3. 解释什么是梯度消失问题，以及LSTM是如何通过其结构设计来缓解这个问题的。

### 4. 描述双向LSTM(Bi-LSTM)的工作原理和应用场景。

## 编程题

### 1. 实现一个简单的LSTM单元

### 2. 使用LSTM进行序列预测

### 3. 比较LSTM和GRU的性能

### 4. 实现字符级语言模型

---

## 答案解析

### 选择题答案
1. **C** - 能够处理长期依赖问题
2. **B** - 决定遗忘细胞状态中的哪些信息
3. **C** - 传递长期信息的"传送带"
4. **C** - 参数更少，结构更简洁
5. **C** - 序列太长且使用简单RNN

### 填空题答案
1. **遗忘**，**输入**，**输出**
2. **f_t**，**i_t**
3. **更新**，**重置**
4. **0**，**1**
5. **初始**

### 简答题答案要点

#### 1. LSTM三个门的工作原理：

**遗忘门 (Forget Gate):**
- 公式：f_t = σ(W_f · [h_{t-1}, x_t] + b_f)
- 作用：决定从细胞状态中丢弃什么信息

**输入门 (Input Gate):**
- 公式：i_t = σ(W_i · [h_{t-1}, x_t] + b_i)
- 候选值：C̃_t = tanh(W_C · [h_{t-1}, x_t] + b_C)
- 作用：决定在细胞状态中存储什么新信息

**输出门 (Output Gate):**
- 公式：o_t = σ(W_o · [h_{t-1}, x_t] + b_o)
- 隐藏状态：h_t = o_t * tanh(C_t)
- 作用：决定输出细胞状态的哪些部分

#### 2. LSTM vs GRU比较：

**LSTM优势：**
- 更精细的门控机制
- 细胞状态和隐藏状态分离
- 理论上能处理更复杂的长期依赖

**GRU优势：**
- 参数更少，训练更快
- 结构更简洁，实现更容易
- 在许多任务上性能与LSTM相当

#### 3. 梯度消失问题及LSTM解决方案：

**梯度消失问题：**
- 在长序列中，梯度在反向传播时逐渐衰减
- 导致网络难以学习长期依赖关系

**LSTM解决方案：**
- 细胞状态提供了梯度的"高速公路"
- 加法操作（而非乘法）保持梯度流
- 门控机制允许选择性地保留和遗忘信息

#### 4. 双向LSTM (Bi-LSTM)：

**工作原理：**
- 同时使用前向和后向LSTM
- 前向LSTM处理序列从左到右
- 后向LSTM处理序列从右到左
- 最终输出结合两个方向的信息

**应用场景：**
- 自然语言处理（词性标注、命名实体识别）
- 语音识别、机器翻译
- 任何需要上下文信息的序列任务 
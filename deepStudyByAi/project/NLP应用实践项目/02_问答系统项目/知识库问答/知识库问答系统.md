# 知识库问答系统
# Knowledge Base Question Answering System

**让机器访问结构化知识回答问题 - 构建智能知识问答系统**
**Making machines access structured knowledge to answer questions - Building intelligent knowledge QA systems**

---

## 🧠 什么是知识库问答？| What is Knowledge Base Question Answering?

知识库问答(KBQA)就像给机器配备了一个"百科全书大脑"。与传统的阅读理解不同，KBQA需要机器理解自然语言问题，然后在结构化的知识库中查找和推理，最终给出准确答案。

Knowledge Base Question Answering (KBQA) is like equipping machines with an "encyclopedia brain". Unlike traditional reading comprehension, KBQA requires machines to understand natural language questions, then search and reason in structured knowledge bases to provide accurate answers.

### KBQA vs 传统QA的区别 | Differences between KBQA and Traditional QA

| 特性 | 传统阅读理解QA | 知识库QA |
|------|----------------|----------|
| **数据源** | 非结构化文本 | 结构化知识图谱 |
| **Data Source** | Unstructured text | Structured knowledge graph |
| **知识范围** | 单篇文档 | 整个知识库 |
| **Knowledge Scope** | Single document | Entire knowledge base |
| **推理能力** | 局部推理 | 多跳全局推理 |
| **Reasoning** | Local reasoning | Multi-hop global reasoning |
| **答案类型** | 文本片段 | 实体、数值、布尔值 |
| **Answer Type** | Text spans | Entities, numbers, boolean |

### 知识库的结构 | Structure of Knowledge Base

**知识图谱的基本组成:**
**Basic Components of Knowledge Graph:**

```
实体 (Entity): 现实世界的对象，如"北京"、"苹果公司"
Entity: Real-world objects like "Beijing", "Apple Inc."

关系 (Relation): 实体之间的联系，如"位于"、"创始人"
Relation: Connections between entities like "located_in", "founder"

属性 (Attribute): 实体的特征，如"人口"、"成立时间"
Attribute: Characteristics of entities like "population", "founded_date"

三元组 (Triple): (头实体, 关系, 尾实体)
Triple: (head_entity, relation, tail_entity)
```

**示例知识图谱:**
**Example Knowledge Graph:**
```
(苹果公司, 创始人, 史蒂夫·乔布斯)
(Apple Inc., founder, Steve Jobs)

(苹果公司, 总部位于, 库比蒂诺)
(Apple Inc., headquarters, Cupertino)

(史蒂夫·乔布斯, 出生日期, 1955-02-24)
(Steve Jobs, birth_date, 1955-02-24)

(库比蒂诺, 位于, 加利福尼亚州)
(Cupertino, located_in, California)
```

## 🔬 KBQA系统架构 | KBQA System Architecture

### 核心组件 | Core Components

```python
class KBQASystem:
    """
    知识库问答系统架构
    Knowledge Base QA System Architecture
    """
    def __init__(self):
        # 1. 问题理解模块 | Question Understanding Module
        self.question_parser = QuestionParser()
        
        # 2. 实体链接模块 | Entity Linking Module  
        self.entity_linker = EntityLinker()
        
        # 3. 关系识别模块 | Relation Recognition Module
        self.relation_classifier = RelationClassifier()
        
        # 4. 查询生成模块 | Query Generation Module
        self.query_generator = QueryGenerator()
        
        # 5. 知识库检索模块 | Knowledge Base Retrieval Module
        self.kb_retriever = KnowledgeBaseRetriever()
        
        # 6. 答案生成模块 | Answer Generation Module
        self.answer_generator = AnswerGenerator()
    
    def answer_question(self, question):
        """
        回答问题的完整流程
        Complete pipeline for answering questions
        """
        # 步骤1: 问题解析
        # Step 1: Question parsing
        parsed_question = self.question_parser.parse(question)
        
        # 步骤2: 实体识别和链接
        # Step 2: Entity recognition and linking
        entities = self.entity_linker.link(parsed_question)
        
        # 步骤3: 关系识别
        # Step 3: Relation recognition
        relations = self.relation_classifier.classify(parsed_question, entities)
        
        # 步骤4: 查询生成
        # Step 4: Query generation
        queries = self.query_generator.generate(entities, relations, parsed_question)
        
        # 步骤5: 知识库检索
        # Step 5: Knowledge base retrieval
        results = self.kb_retriever.retrieve(queries)
        
        # 步骤6: 答案生成
        # Step 6: Answer generation
        answer = self.answer_generator.generate(results, parsed_question)
        
        return answer
```

### 技术挑战与解决方案 | Technical Challenges and Solutions

#### 1. 实体链接 (Entity Linking)

**挑战**: 自然语言中的实体提及可能有歧义性
**Challenge**: Entity mentions in natural language can be ambiguous

```python
import torch
import torch.nn as nn
from transformers import BertModel, BertTokenizer

class EntityLinker:
    """
    实体链接器
    Entity Linker
    
    将自然语言中的实体提及链接到知识库中的标准实体
    Link entity mentions in natural language to canonical entities in KB
    """
    
    def __init__(self, kb_entities, model_name='bert-base-uncased'):
        self.kb_entities = kb_entities  # 知识库中的所有实体
        self.tokenizer = BertTokenizer.from_pretrained(model_name)
        self.bert = BertModel.from_pretrained(model_name)
        
        # 预计算所有实体的向量表示
        # Pre-compute vector representations for all entities
        self.entity_embeddings = self.compute_entity_embeddings()
        
        # 相似度阈值
        # Similarity threshold
        self.similarity_threshold = 0.7
    
    def compute_entity_embeddings(self):
        """
        预计算实体嵌入
        Pre-compute entity embeddings
        """
        embeddings = {}
        
        for entity_id, entity_info in self.kb_entities.items():
            # 使用实体名称和描述计算嵌入
            # Compute embedding using entity name and description
            text = f"{entity_info['name']} {entity_info.get('description', '')}"
            
            inputs = self.tokenizer(text, return_tensors='pt', max_length=128, truncation=True)
            with torch.no_grad():
                outputs = self.bert(**inputs)
                embedding = outputs.pooler_output.squeeze().numpy()
            
            embeddings[entity_id] = embedding
        
        return embeddings
    
    def link_entities(self, question):
        """
        在问题中链接实体
        Link entities in question
        """
        # 首先识别候选实体提及
        # First identify candidate entity mentions
        mentions = self.extract_entity_mentions(question)
        
        linked_entities = []
        
        for mention in mentions:
            # 计算提及的向量表示
            # Compute vector representation of mention
            mention_embedding = self.compute_mention_embedding(mention)
            
            # 找到最相似的实体
            # Find most similar entity
            best_entity = self.find_best_entity(mention_embedding)
            
            if best_entity:
                linked_entities.append({
                    'mention': mention['text'],
                    'entity_id': best_entity['id'],
                    'entity_name': best_entity['name'],
                    'confidence': best_entity['similarity'],
                    'start': mention['start'],
                    'end': mention['end']
                })
        
        return linked_entities
    
    def extract_entity_mentions(self, question):
        """
        提取实体提及
        Extract entity mentions
        """
        # 使用NER模型提取实体
        # Use NER model to extract entities
        from transformers import pipeline
        
        ner = pipeline("ner", model="dbmdz/bert-large-cased-finetuned-conll03-english")
        entities = ner(question)
        
        mentions = []
        for entity in entities:
            mentions.append({
                'text': entity['word'],
                'start': entity['start'],
                'end': entity['end'],
                'type': entity['entity']
            })
        
        return mentions
    
    def compute_mention_embedding(self, mention):
        """
        计算提及的嵌入表示
        Compute embedding representation of mention
        """
        inputs = self.tokenizer(mention['text'], return_tensors='pt')
        with torch.no_grad():
            outputs = self.bert(**inputs)
            embedding = outputs.pooler_output.squeeze().numpy()
        
        return embedding
    
    def find_best_entity(self, mention_embedding):
        """
        找到最匹配的实体
        Find best matching entity
        """
        best_similarity = 0
        best_entity = None
        
        for entity_id, entity_embedding in self.entity_embeddings.items():
            # 计算余弦相似度
            # Compute cosine similarity
            similarity = self.cosine_similarity(mention_embedding, entity_embedding)
            
            if similarity > best_similarity and similarity > self.similarity_threshold:
                best_similarity = similarity
                best_entity = {
                    'id': entity_id,
                    'name': self.kb_entities[entity_id]['name'],
                    'similarity': similarity
                }
        
        return best_entity
    
    def cosine_similarity(self, vec1, vec2):
        """
        计算余弦相似度
        Compute cosine similarity
        """
        import numpy as np
        
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0
        
        return dot_product / (norm1 * norm2)
```

#### 2. 关系分类 (Relation Classification)

**挑战**: 理解问题中隐含的关系类型
**Challenge**: Understanding implicit relation types in questions

```python
class RelationClassifier:
    """
    关系分类器
    Relation Classifier
    
    识别问题中涉及的关系类型
    Identify relation types involved in questions
    """
    
    def __init__(self, relation_vocab, model_name='bert-base-uncased'):
        self.relation_vocab = relation_vocab
        self.tokenizer = BertTokenizer.from_pretrained(model_name)
        self.model = self.build_relation_classifier(model_name)
        
        # 关系模板 | Relation templates
        self.relation_templates = {
            'birth_date': ['when was', 'birth', 'born'],
            'death_date': ['when did', 'death', 'died'],
            'location': ['where', 'located', 'place'],
            'founder': ['who founded', 'founder', 'established by'],
            'capital': ['capital of', 'capital city'],
            'population': ['population', 'how many people']
        }
    
    def build_relation_classifier(self, model_name):
        """
        构建关系分类模型
        Build relation classification model
        """
        class RelationBERT(nn.Module):
            def __init__(self, model_name, num_relations):
                super().__init__()
                self.bert = BertModel.from_pretrained(model_name)
                self.dropout = nn.Dropout(0.1)
                self.classifier = nn.Linear(self.bert.config.hidden_size, num_relations)
            
            def forward(self, input_ids, attention_mask):
                outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
                pooled_output = self.dropout(outputs.pooler_output)
                logits = self.classifier(pooled_output)
                return logits
        
        model = RelationBERT(model_name, len(self.relation_vocab))
        return model
    
    def classify_relations(self, question, entities):
        """
        分类问题中的关系
        Classify relations in question
        """
        # 方法1: 基于模板的关系识别
        # Method 1: Template-based relation recognition
        template_relations = self.template_based_classification(question)
        
        # 方法2: 基于深度学习的关系分类
        # Method 2: Deep learning-based relation classification
        ml_relations = self.ml_based_classification(question, entities)
        
        # 融合两种方法的结果
        # Combine results from both methods
        relations = self.combine_relation_predictions(template_relations, ml_relations)
        
        return relations
    
    def template_based_classification(self, question):
        """
        基于模板的关系分类
        Template-based relation classification
        """
        question_lower = question.lower()
        detected_relations = []
        
        for relation, templates in self.relation_templates.items():
            for template in templates:
                if template in question_lower:
                    detected_relations.append({
                        'relation': relation,
                        'confidence': 0.9,  # 模板匹配的高置信度
                        'method': 'template'
                    })
                    break
        
        return detected_relations
    
    def ml_based_classification(self, question, entities):
        """
        基于机器学习的关系分类
        Machine learning-based relation classification
        """
        # 构造输入：问题 + 实体
        # Construct input: question + entities
        entity_text = " ".join([entity['entity_name'] for entity in entities])
        input_text = f"{question} [SEP] {entity_text}"
        
        # 编码
        # Encode
        inputs = self.tokenizer(
            input_text,
            return_tensors='pt',
            max_length=128,
            truncation=True,
            padding=True
        )
        
        # 预测
        # Predict
        with torch.no_grad():
            logits = self.model(**inputs)
            probabilities = torch.softmax(logits, dim=-1)
            
            # 获取top-k关系
            # Get top-k relations
            top_k = 3
            top_probs, top_indices = torch.topk(probabilities, k=top_k, dim=-1)
            
            relations = []
            for i in range(top_k):
                relation_id = top_indices[0][i].item()
                confidence = top_probs[0][i].item()
                
                if confidence > 0.3:  # 置信度阈值
                    relation_name = list(self.relation_vocab.keys())[relation_id]
                    relations.append({
                        'relation': relation_name,
                        'confidence': confidence,
                        'method': 'ml'
                    })
        
        return relations
    
    def combine_relation_predictions(self, template_relations, ml_relations):
        """
        融合关系预测结果
        Combine relation prediction results
        """
        # 创建关系置信度字典
        # Create relation confidence dictionary
        relation_scores = defaultdict(float)
        
        # 加权融合
        # Weighted fusion
        for rel in template_relations:
            relation_scores[rel['relation']] += rel['confidence'] * 0.7
        
        for rel in ml_relations:
            relation_scores[rel['relation']] += rel['confidence'] * 0.3
        
        # 排序并返回
        # Sort and return
        final_relations = []
        for relation, score in sorted(relation_scores.items(), key=lambda x: x[1], reverse=True):
            if score > 0.4:
                final_relations.append({
                    'relation': relation,
                    'confidence': score
                })
        
        return final_relations
```

#### 3. 查询生成 (Query Generation)

**挑战**: 将自然语言问题转换为结构化查询
**Challenge**: Convert natural language questions to structured queries

```python
class SPARQLQueryGenerator:
    """
    SPARQL查询生成器
    SPARQL Query Generator
    
    将自然语言问题转换为SPARQL查询
    Convert natural language questions to SPARQL queries
    """
    
    def __init__(self, knowledge_base):
        self.kb = knowledge_base
        self.query_templates = self.load_query_templates()
    
    def load_query_templates(self):
        """
        加载查询模板
        Load query templates
        """
        templates = {
            # 单跳查询模板 | Single-hop query templates
            'single_hop': {
                'attribute_query': """
                    SELECT ?answer WHERE {
                        <{entity}> <{relation}> ?answer .
                    }
                """,
                'reverse_query': """
                    SELECT ?answer WHERE {
                        ?answer <{relation}> <{entity}> .
                    }
                """
            },
            
            # 多跳查询模板 | Multi-hop query templates
            'multi_hop': {
                'two_hop': """
                    SELECT ?answer WHERE {
                        <{entity1}> <{relation1}> ?intermediate .
                        ?intermediate <{relation2}> ?answer .
                    }
                """,
                'three_hop': """
                    SELECT ?answer WHERE {
                        <{entity1}> <{relation1}> ?intermediate1 .
                        ?intermediate1 <{relation2}> ?intermediate2 .
                        ?intermediate2 <{relation3}> ?answer .
                    }
                """
            },
            
            # 聚合查询模板 | Aggregation query templates
            'aggregation': {
                'count': """
                    SELECT (COUNT(?answer) AS ?count) WHERE {
                        <{entity}> <{relation}> ?answer .
                    }
                """,
                'max': """
                    SELECT (MAX(?answer) AS ?max) WHERE {
                        <{entity}> <{relation}> ?answer .
                    }
                """
            }
        }
        
        return templates
    
    def generate_queries(self, entities, relations, question_type):
        """
        生成SPARQL查询
        Generate SPARQL queries
        """
        queries = []
        
        # 根据问题类型生成不同的查询
        # Generate different queries based on question type
        if question_type == 'factual':
            queries.extend(self.generate_factual_queries(entities, relations))
        elif question_type == 'count':
            queries.extend(self.generate_count_queries(entities, relations))
        elif question_type == 'comparison':
            queries.extend(self.generate_comparison_queries(entities, relations))
        
        return queries
    
    def generate_factual_queries(self, entities, relations):
        """
        生成事实性查询
        Generate factual queries
        """
        queries = []
        
        for entity in entities:
            for relation in relations:
                # 单跳查询
                # Single-hop query
                query = self.query_templates['single_hop']['attribute_query'].format(
                    entity=entity['entity_id'],
                    relation=relation['relation']
                )
                queries.append({
                    'sparql': query,
                    'type': 'single_hop',
                    'entities': [entity],
                    'relations': [relation]
                })
                
                # 反向查询
                # Reverse query
                reverse_query = self.query_templates['single_hop']['reverse_query'].format(
                    entity=entity['entity_id'],
                    relation=relation['relation']
                )
                queries.append({
                    'sparql': reverse_query,
                    'type': 'reverse',
                    'entities': [entity],
                    'relations': [relation]
                })
        
        # 多跳查询
        # Multi-hop queries
        if len(entities) > 1 and len(relations) > 1:
            multi_hop_query = self.query_templates['multi_hop']['two_hop'].format(
                entity1=entities[0]['entity_id'],
                relation1=relations[0]['relation'],
                relation2=relations[1]['relation']
            )
            queries.append({
                'sparql': multi_hop_query,
                'type': 'multi_hop',
                'entities': entities[:1],
                'relations': relations[:2]
            })
        
        return queries
    
    def generate_count_queries(self, entities, relations):
        """
        生成计数查询
        Generate count queries
        """
        queries = []
        
        for entity in entities:
            for relation in relations:
                query = self.query_templates['aggregation']['count'].format(
                    entity=entity['entity_id'],
                    relation=relation['relation']
                )
                queries.append({
                    'sparql': query,
                    'type': 'count',
                    'entities': [entity],
                    'relations': [relation]
                })
        
        return queries
    
    def execute_query(self, sparql_query):
        """
        执行SPARQL查询
        Execute SPARQL query
        """
        try:
            # 在实际系统中，这里会连接到真实的知识库
            # In actual systems, this would connect to a real knowledge base
            results = self.kb.query(sparql_query)
            return {
                'success': True,
                'results': results,
                'query': sparql_query
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'query': sparql_query
            }
```

#### 4. 多跳推理 (Multi-hop Reasoning)

**挑战**: 处理需要多步推理的复杂问题
**Challenge**: Handle complex questions requiring multi-step reasoning

```python
class MultiHopReasoner:
    """
    多跳推理器
    Multi-hop Reasoner
    
    处理需要多步推理的复杂问答
    Handle complex QA requiring multi-step reasoning
    """
    
    def __init__(self, knowledge_base, max_hops=3):
        self.kb = knowledge_base
        self.max_hops = max_hops
        self.reasoning_cache = {}  # 推理缓存
    
    def reason(self, question, entities, target_type=None):
        """
        执行多跳推理
        Execute multi-hop reasoning
        """
        # 初始化推理状态
        # Initialize reasoning state
        reasoning_paths = []
        
        for entity in entities:
            # 从每个实体开始进行广度优先搜索
            # Start breadth-first search from each entity
            paths = self.bfs_reasoning(entity, target_type)
            reasoning_paths.extend(paths)
        
        # 评估和排序推理路径
        # Evaluate and rank reasoning paths
        ranked_paths = self.rank_reasoning_paths(reasoning_paths, question)
        
        return ranked_paths
    
    def bfs_reasoning(self, start_entity, target_type=None):
        """
        广度优先搜索推理
        Breadth-first search reasoning
        """
        from collections import deque
        
        # 初始化搜索队列
        # Initialize search queue
        queue = deque([(start_entity, [], 0)])  # (实体, 路径, 跳数)
        visited = set()
        reasoning_paths = []
        
        while queue and len(reasoning_paths) < 100:  # 限制路径数量
            current_entity, path, hops = queue.popleft()
            
            if hops >= self.max_hops:
                continue
            
            if current_entity['entity_id'] in visited:
                continue
            
            visited.add(current_entity['entity_id'])
            
            # 获取当前实体的所有关系
            # Get all relations of current entity
            relations = self.kb.get_entity_relations(current_entity['entity_id'])
            
            for relation, target_entities in relations.items():
                for target_entity in target_entities:
                    new_path = path + [(current_entity, relation, target_entity)]
                    
                    # 如果找到目标类型的实体，记录路径
                    # If target type entity found, record path
                    if target_type is None or self.kb.get_entity_type(target_entity) == target_type:
                        reasoning_paths.append({
                            'path': new_path,
                            'start_entity': start_entity,
                            'end_entity': target_entity,
                            'hops': hops + 1,
                            'confidence': self.calculate_path_confidence(new_path)
                        })
                    
                    # 继续搜索
                    # Continue searching
                    if hops + 1 < self.max_hops:
                        queue.append((
                            {'entity_id': target_entity, 'entity_name': self.kb.get_entity_name(target_entity)},
                            new_path,
                            hops + 1
                        ))
        
        return reasoning_paths
    
    def calculate_path_confidence(self, path):
        """
        计算推理路径的置信度
        Calculate confidence of reasoning path
        """
        if not path:
            return 0.0
        
        # 基于路径长度的惩罚
        # Penalty based on path length
        length_penalty = 0.8 ** len(path)
        
        # 基于关系频率的奖励
        # Reward based on relation frequency
        relation_scores = []
        for _, relation, _ in path:
            relation_freq = self.kb.get_relation_frequency(relation)
            relation_scores.append(relation_freq)
        
        avg_relation_score = sum(relation_scores) / len(relation_scores)
        
        # 综合置信度
        # Combined confidence
        confidence = length_penalty * avg_relation_score
        
        return confidence
    
    def rank_reasoning_paths(self, paths, question):
        """
        对推理路径进行排序
        Rank reasoning paths
        """
        # 计算每条路径与问题的相关性
        # Calculate relevance of each path to question
        for path in paths:
            relevance_score = self.calculate_question_relevance(path, question)
            path['total_score'] = path['confidence'] * relevance_score
        
        # 按总分排序
        # Sort by total score
        paths.sort(key=lambda x: x['total_score'], reverse=True)
        
        return paths[:10]  # 返回top-10路径
    
    def calculate_question_relevance(self, path, question):
        """
        计算路径与问题的相关性
        Calculate relevance between path and question
        """
        # 简化的相关性计算
        # Simplified relevance calculation
        question_words = set(question.lower().split())
        
        path_words = set()
        for entity1, relation, entity2 in path['path']:
            path_words.update(entity1['entity_name'].lower().split())
            path_words.update(relation.lower().split('_'))
            path_words.update(self.kb.get_entity_name(entity2).lower().split())
        
        # 计算词汇重叠
        # Calculate word overlap
        overlap = len(question_words & path_words)
        total_words = len(question_words | path_words)
        
        if total_words == 0:
            return 0.0
        
        return overlap / total_words
```

## 💻 完整KBQA系统实现 | Complete KBQA System Implementation

### 知识库接口 | Knowledge Base Interface

```python
class KnowledgeBase:
    """
    知识库接口
    Knowledge Base Interface
    
    提供对结构化知识的访问接口
    Provides access interface to structured knowledge
    """
    
    def __init__(self, kb_path):
        self.kb_path = kb_path
        self.entities = {}
        self.relations = {}
        self.triples = []
        self.load_knowledge_base()
    
    def load_knowledge_base(self):
        """
        加载知识库
        Load knowledge base
        """
        # 加载实体
        # Load entities
        with open(f"{self.kb_path}/entities.json", 'r', encoding='utf-8') as f:
            self.entities = json.load(f)
        
        # 加载关系
        # Load relations
        with open(f"{self.kb_path}/relations.json", 'r', encoding='utf-8') as f:
            self.relations = json.load(f)
        
        # 加载三元组
        # Load triples
        with open(f"{self.kb_path}/triples.json", 'r', encoding='utf-8') as f:
            self.triples = json.load(f)
        
        # 构建索引
        # Build indices
        self.build_indices()
    
    def build_indices(self):
        """
        构建索引以加速查询
        Build indices for faster queries
        """
        self.entity_relations = defaultdict(lambda: defaultdict(list))
        self.relation_entities = defaultdict(list)
        
        for triple in self.triples:
            head, relation, tail = triple['head'], triple['relation'], triple['tail']
            
            # 实体-关系索引
            # Entity-relation index
            self.entity_relations[head][relation].append(tail)
            self.entity_relations[tail][f"reverse_{relation}"].append(head)
            
            # 关系-实体索引
            # Relation-entity index
            self.relation_entities[relation].append((head, tail))
    
    def get_entity_relations(self, entity_id):
        """
        获取实体的所有关系
        Get all relations of an entity
        """
        return dict(self.entity_relations.get(entity_id, {}))
    
    def get_relation_entities(self, relation):
        """
        获取关系涉及的所有实体对
        Get all entity pairs involved in a relation
        """
        return self.relation_entities.get(relation, [])
    
    def query_single_hop(self, entity_id, relation):
        """
        单跳查询
        Single-hop query
        """
        return self.entity_relations.get(entity_id, {}).get(relation, [])
    
    def query_multi_hop(self, start_entity, relations):
        """
        多跳查询
        Multi-hop query
        """
        current_entities = [start_entity]
        
        for relation in relations:
            next_entities = []
            for entity in current_entities:
                next_entities.extend(self.query_single_hop(entity, relation))
            current_entities = list(set(next_entities))
        
        return current_entities
    
    def get_entity_info(self, entity_id):
        """
        获取实体信息
        Get entity information
        """
        return self.entities.get(entity_id, {})
    
    def get_entity_name(self, entity_id):
        """
        获取实体名称
        Get entity name
        """
        return self.entities.get(entity_id, {}).get('name', entity_id)
    
    def get_entity_type(self, entity_id):
        """
        获取实体类型
        Get entity type
        """
        return self.entities.get(entity_id, {}).get('type', 'unknown')
    
    def get_relation_frequency(self, relation):
        """
        获取关系频率
        Get relation frequency
        """
        return len(self.relation_entities.get(relation, []))
```

### 集成系统 | Integrated System

```python
class CompleteKBQASystem:
    """
    完整的知识库问答系统
    Complete Knowledge Base QA System
    """
    
    def __init__(self, kb_path, model_configs=None):
        # 初始化知识库
        # Initialize knowledge base
        self.kb = KnowledgeBase(kb_path)
        
        # 初始化各组件
        # Initialize components
        self.entity_linker = EntityLinker(self.kb.entities)
        self.relation_classifier = RelationClassifier(self.kb.relations)
        self.query_generator = SPARQLQueryGenerator(self.kb)
        self.multi_hop_reasoner = MultiHopReasoner(self.kb)
        
        # 问题类型分类器
        # Question type classifier
        self.question_classifier = self.build_question_classifier()
    
    def build_question_classifier(self):
        """
        构建问题类型分类器
        Build question type classifier
        """
        # 问题类型模板
        # Question type templates
        templates = {
            'factual': ['what is', 'who is', 'where is', 'when was'],
            'count': ['how many', 'count of', 'number of'],
            'comparison': ['compare', 'difference', 'better than'],
            'yes_no': ['is', 'does', 'can', 'will'],
            'list': ['list', 'all', 'which']
        }
        
        return templates
    
    def classify_question_type(self, question):
        """
        分类问题类型
        Classify question type
        """
        question_lower = question.lower()
        
        for q_type, templates in self.question_classifier.items():
            for template in templates:
                if template in question_lower:
                    return q_type
        
        return 'factual'  # 默认类型
    
    def answer_question(self, question):
        """
        回答问题
        Answer question
        """
        try:
            # 步骤1: 问题类型分类
            # Step 1: Question type classification
            question_type = self.classify_question_type(question)
            
            # 步骤2: 实体链接
            # Step 2: Entity linking
            entities = self.entity_linker.link_entities(question)
            
            if not entities:
                return {
                    'answer': "抱歉，我无法识别问题中的实体。",
                    'confidence': 0.0,
                    'reasoning': []
                }
            
            # 步骤3: 关系分类
            # Step 3: Relation classification
            relations = self.relation_classifier.classify_relations(question, entities)
            
            if not relations:
                return {
                    'answer': "抱歉，我无法理解问题中的关系。",
                    'confidence': 0.0,
                    'reasoning': []
                }
            
            # 步骤4: 查询生成和执行
            # Step 4: Query generation and execution
            answers = []
            
            if question_type in ['factual', 'yes_no']:
                answers = self.handle_factual_question(entities, relations)
            elif question_type == 'count':
                answers = self.handle_count_question(entities, relations)
            elif question_type == 'list':
                answers = self.handle_list_question(entities, relations)
            
            # 如果简单查询没有结果，尝试多跳推理
            # If simple queries have no results, try multi-hop reasoning
            if not answers:
                reasoning_paths = self.multi_hop_reasoner.reason(question, entities)
                if reasoning_paths:
                    best_path = reasoning_paths[0]
                    answers = [best_path['end_entity']]
            
            # 格式化答案
            # Format answer
            if answers:
                formatted_answer = self.format_answer(answers, question_type)
                return {
                    'answer': formatted_answer,
                    'confidence': 0.8,
                    'entities': entities,
                    'relations': relations,
                    'reasoning': reasoning_paths[:3] if 'reasoning_paths' in locals() else []
                }
            else:
                return {
                    'answer': "抱歉，我无法在知识库中找到相关信息。",
                    'confidence': 0.0,
                    'reasoning': []
                }
                
        except Exception as e:
            return {
                'answer': f"处理问题时出现错误: {str(e)}",
                'confidence': 0.0,
                'reasoning': []
            }
    
    def handle_factual_question(self, entities, relations):
        """
        处理事实性问题
        Handle factual questions
        """
        answers = []
        
        for entity in entities:
            for relation in relations:
                # 单跳查询
                # Single-hop query
                results = self.kb.query_single_hop(entity['entity_id'], relation['relation'])
                answers.extend(results)
                
                # 反向查询
                # Reverse query
                reverse_results = self.kb.query_single_hop(entity['entity_id'], f"reverse_{relation['relation']}")
                answers.extend(reverse_results)
        
        return list(set(answers))  # 去重
    
    def handle_count_question(self, entities, relations):
        """
        处理计数问题
        Handle count questions
        """
        total_count = 0
        
        for entity in entities:
            for relation in relations:
                results = self.kb.query_single_hop(entity['entity_id'], relation['relation'])
                total_count += len(results)
        
        return [str(total_count)]
    
    def handle_list_question(self, entities, relations):
        """
        处理列表问题
        Handle list questions
        """
        all_answers = []
        
        for entity in entities:
            for relation in relations:
                results = self.kb.query_single_hop(entity['entity_id'], relation['relation'])
                all_answers.extend(results)
        
        return list(set(all_answers))  # 去重
    
    def format_answer(self, answers, question_type):
        """
        格式化答案
        Format answer
        """
        if not answers:
            return "没有找到相关信息。"
        
        # 将实体ID转换为可读名称
        # Convert entity IDs to readable names
        readable_answers = []
        for answer in answers:
            if answer in self.kb.entities:
                readable_answers.append(self.kb.get_entity_name(answer))
            else:
                readable_answers.append(str(answer))
        
        if question_type == 'count':
            return f"数量是: {readable_answers[0]}"
        elif question_type == 'list':
            return "结果包括: " + ", ".join(readable_answers[:10])  # 限制显示数量
        else:
            return readable_answers[0] if readable_answers else "没有找到答案。"


def main():
    """
    演示KBQA系统的使用
    Demonstrate KBQA system usage
    """
    # 创建示例知识库
    # Create example knowledge base
    kb_path = "example_kb"
    
    # 初始化KBQA系统
    # Initialize KBQA system
    kbqa_system = CompleteKBQASystem(kb_path)
    
    # 测试问题
    # Test questions
    test_questions = [
        "苹果公司的创始人是谁？",
        "史蒂夫·乔布斯什么时候出生的？",
        "有多少家公司的总部在加利福尼亚？",
        "列出所有位于纽约的大学。"
    ]
    
    print("=== 知识库问答系统演示 | KBQA System Demo ===")
    
    for question in test_questions:
        print(f"\n问题 | Question: {question}")
        result = kbqa_system.answer_question(question)
        print(f"答案 | Answer: {result['answer']}")
        print(f"置信度 | Confidence: {result['confidence']:.2f}")
        
        if result['reasoning']:
            print("推理路径 | Reasoning Path:")
            for i, path in enumerate(result['reasoning'][:2]):
                print(f"  路径{i+1}: {path}")


if __name__ == "__main__":
    main()
```

通过这个知识库问答系统项目，你将学会如何让机器理解结构化知识，实现真正的智能问答！这是构建下一代AI助手的关键技术。

Through this knowledge base QA system project, you will learn how to make machines understand structured knowledge and achieve truly intelligent question answering! This is a key technology for building next-generation AI assistants. 
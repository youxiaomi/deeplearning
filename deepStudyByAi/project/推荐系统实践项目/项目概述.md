# æ¨èç³»ç»Ÿå®è·µé¡¹ç›®æ¦‚è¿°
# Recommender Systems Practice Project Overview

**ä¸ªæ€§åŒ–AIçš„æ ¸å¿ƒ - è®©æ¯ä¸ªç”¨æˆ·éƒ½è·å¾—é‡èº«å®šåˆ¶çš„ä½“éªŒ**
**The Core of Personalized AI - Giving Every User a Tailored Experience**

---

## ğŸ¯ é¡¹ç›®ç›®æ ‡ | Project Goals

æ¨èç³»ç»Ÿæ˜¯ç°ä»£äº’è”ç½‘æœ€æˆåŠŸçš„AIåº”ç”¨ä¹‹ä¸€ï¼ä»ç”µå•†è´­ç‰©åˆ°è§†é¢‘å¨±ä¹ï¼Œä»æ–°é—»é˜…è¯»åˆ°éŸ³ä¹æ¬£èµï¼Œæ¨èç³»ç»Ÿæ— å¤„ä¸åœ¨ã€‚é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œä½ å°†æŒæ¡ï¼š
Recommender systems are one of the most successful AI applications in the modern internet! From e-commerce shopping to video entertainment, from news reading to music appreciation, recommender systems are everywhere. Through this project, you will master:

- **ååŒè¿‡æ»¤ç®—æ³•** | **Collaborative Filtering**: åŸºäºç”¨æˆ·è¡Œä¸ºçš„æ¨èæ ¸å¿ƒæŠ€æœ¯
- **å†…å®¹æ¨èç³»ç»Ÿ** | **Content-based Recommendation**: åŸºäºç‰©å“ç‰¹å¾çš„æ¨èæ–¹æ³•
- **æ·±åº¦å­¦ä¹ æ¨è** | **Deep Learning Recommendation**: ç°ä»£æ¨èç³»ç»Ÿçš„å‰æ²¿æŠ€æœ¯
- **å®é™…éƒ¨ç½²åº”ç”¨** | **Real Deployment**: æ„å»ºå¯æ‰©å±•çš„æ¨èæœåŠ¡ç³»ç»Ÿ

## ğŸ”¬ ä¸ºä»€ä¹ˆæ¨èç³»ç»Ÿå¦‚æ­¤é‡è¦ï¼Ÿ| Why are Recommender Systems So Important?

**æ¨èç³»ç»Ÿæ­£åœ¨é‡å¡‘ä¿¡æ¯æ¶ˆè´¹çš„æ–¹å¼ï¼**
**Recommender systems are reshaping the way we consume information!**

Netflixçš„ä¸ªæ€§åŒ–æ¨èè´¡çŒ®äº†80%çš„è§‚çœ‹æ—¶é—´ï¼ŒAmazonçš„æ¨èç®—æ³•å¸¦æ¥äº†35%çš„é”€å”®é¢ï¼ŒTikTokçš„æ¨èç®—æ³•è®©ç”¨æˆ·å¹³å‡ä½¿ç”¨æ—¶é•¿è¶…è¿‡90åˆ†é’Ÿã€‚æ¨èç³»ç»Ÿä¸ä»…æ˜¯æŠ€æœ¯ï¼Œæ›´æ˜¯è¿æ¥ç”¨æˆ·ä¸å†…å®¹çš„æ™ºèƒ½æ¡¥æ¢ï¼Œåˆ›é€ äº†æ•°åƒäº¿ç¾å…ƒçš„å•†ä¸šä»·å€¼ã€‚

Netflix's personalized recommendations contribute to 80% of viewing time, Amazon's recommendation algorithm brings 35% of sales, and TikTok's recommendation algorithm makes users spend an average of over 90 minutes. Recommender systems are not just technology, but intelligent bridges connecting users with content, creating hundreds of billions of dollars in business value.

### æ¨èç³»ç»Ÿçš„å‘å±•å†ç¨‹ | Evolution of Recommender Systems
```
1990s: ååŒè¿‡æ»¤èµ·æº | Origin of Collaborative Filtering
2000s: çŸ©é˜µåˆ†è§£æŠ€æœ¯ | Matrix Factorization Techniques
2010s: æ·±åº¦å­¦ä¹ é©å‘½ | Deep Learning Revolution
2015s: ç¥ç»ååŒè¿‡æ»¤ | Neural Collaborative Filtering
2020s: å¤§æ¨¡å‹æ¨è | Large Model Recommendations
```

## ğŸ“š é¡¹ç›®ç»“æ„æ·±åº¦è§£æ | Deep Project Structure Analysis

### 01_ååŒè¿‡æ»¤ç³»ç»Ÿ | Collaborative Filtering Systems

**æŒ–æ˜ç”¨æˆ·è¡Œä¸ºä¸­çš„éšè—æ¨¡å¼ï¼**
**Mine hidden patterns in user behavior!**

#### ç”¨æˆ·ååŒè¿‡æ»¤ | User-based Collaborative Filtering

**é¡¹ç›®æ ¸å¿ƒ | Project Core:**
ç”¨æˆ·ååŒè¿‡æ»¤åŸºäº"ç›¸ä¼¼ç”¨æˆ·å–œæ¬¢ç›¸ä¼¼ç‰©å“"çš„å‡è®¾ï¼Œé€šè¿‡å¯»æ‰¾ç›¸ä¼¼ç”¨æˆ·æ¥è¿›è¡Œæ¨èã€‚

User-based collaborative filtering is based on the assumption that "similar users like similar items", making recommendations by finding similar users.

**æ ¸å¿ƒç®—æ³•åŸç† | Core Algorithm Principles:**

**ç”¨æˆ·ç›¸ä¼¼åº¦è®¡ç®— | User Similarity Calculation:**
```python
# ä½™å¼¦ç›¸ä¼¼åº¦ | Cosine Similarity
def cosine_similarity(user_a, user_b):
    """
    è®¡ç®—ä¸¤ä¸ªç”¨æˆ·çš„ä½™å¼¦ç›¸ä¼¼åº¦
    Calculate cosine similarity between two users
    """
    dot_product = np.dot(user_a, user_b)
    norm_a = np.linalg.norm(user_a)
    norm_b = np.linalg.norm(user_b)
    
    if norm_a == 0 or norm_b == 0:
        return 0
    
    return dot_product / (norm_a * norm_b)

# çš®å°”é€Šç›¸å…³ç³»æ•° | Pearson Correlation Coefficient
def pearson_correlation(user_a, user_b):
    """
    è®¡ç®—ä¸¤ä¸ªç”¨æˆ·çš„çš®å°”é€Šç›¸å…³ç³»æ•°
    Calculate Pearson correlation coefficient between two users
    """
    # æ‰¾åˆ°ä¸¤ä¸ªç”¨æˆ·éƒ½è¯„åˆ†çš„ç‰©å“
    # Find items rated by both users
    common_items = set(user_a.keys()) & set(user_b.keys())
    
    if len(common_items) == 0:
        return 0
    
    # è®¡ç®—å¹³å‡åˆ† | Calculate mean ratings
    mean_a = np.mean([user_a[item] for item in common_items])
    mean_b = np.mean([user_b[item] for item in common_items])
    
    # è®¡ç®—åæ–¹å·®å’Œæ–¹å·® | Calculate covariance and variance
    numerator = sum((user_a[item] - mean_a) * (user_b[item] - mean_b) 
                   for item in common_items)
    
    var_a = sum((user_a[item] - mean_a) ** 2 for item in common_items)
    var_b = sum((user_b[item] - mean_b) ** 2 for item in common_items)
    
    denominator = np.sqrt(var_a * var_b)
    
    if denominator == 0:
        return 0
    
    return numerator / denominator
```

**å®Œæ•´å®ç° | Complete Implementation:**
```python
import numpy as np
import pandas as pd
from scipy.sparse import csr_matrix
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns

class UserBasedCollaborativeFiltering:
    """
    åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤æ¨èç³»ç»Ÿ
    User-based Collaborative Filtering Recommender System
    """
    def __init__(self, n_neighbors=20, similarity_metric='cosine'):
        self.n_neighbors = n_neighbors
        self.similarity_metric = similarity_metric
        self.user_item_matrix = None
        self.user_similarity_matrix = None
        self.user_mean_ratings = None
        
    def fit(self, ratings_df):
        """
        è®­ç»ƒæ¨èæ¨¡å‹
        Train the recommendation model
        
        Args:
            ratings_df: DataFrame with columns ['user_id', 'item_id', 'rating']
        """
        print("æ„å»ºç”¨æˆ·-ç‰©å“è¯„åˆ†çŸ©é˜µ...")
        print("Building user-item rating matrix...")
        
        # æ„å»ºç”¨æˆ·-ç‰©å“è¯„åˆ†çŸ©é˜µ | Build user-item rating matrix
        self.user_item_matrix = ratings_df.pivot_table(
            index='user_id', 
            columns='item_id', 
            values='rating',
            fill_value=0
        )
        
        # è®¡ç®—ç”¨æˆ·å¹³å‡è¯„åˆ† | Calculate user mean ratings
        self.user_mean_ratings = self.user_item_matrix.mean(axis=1)
        
        print("è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦çŸ©é˜µ...")
        print("Computing user similarity matrix...")
        
        # è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦çŸ©é˜µ | Compute user similarity matrix
        if self.similarity_metric == 'cosine':
            self.user_similarity_matrix = cosine_similarity(self.user_item_matrix)
        elif self.similarity_metric == 'pearson':
            self.user_similarity_matrix = self._compute_pearson_similarity()
        
        # è½¬æ¢ä¸ºDataFrameä¾¿äºå¤„ç† | Convert to DataFrame for easier handling
        self.user_similarity_matrix = pd.DataFrame(
            self.user_similarity_matrix,
            index=self.user_item_matrix.index,
            columns=self.user_item_matrix.index
        )
        
        print("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        print("Model training completed!")
        
        return self
    
    def _compute_pearson_similarity(self):
        """
        è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°ç›¸ä¼¼åº¦çŸ©é˜µ
        Compute Pearson correlation similarity matrix
        """
        # ä¸­å¿ƒåŒ–è¯„åˆ†çŸ©é˜µ | Center the rating matrix
        centered_matrix = self.user_item_matrix.sub(self.user_mean_ratings, axis=0)
        
        # è®¡ç®—ç›¸å…³ç³»æ•° | Compute correlation coefficients
        correlation_matrix = np.corrcoef(centered_matrix.fillna(0))
        
        # å¤„ç†NaNå€¼ | Handle NaN values
        correlation_matrix = np.nan_to_num(correlation_matrix)
        
        return correlation_matrix
    
    def predict_rating(self, user_id, item_id):
        """
        é¢„æµ‹ç”¨æˆ·å¯¹ç‰©å“çš„è¯„åˆ†
        Predict user's rating for an item
        """
        if user_id not in self.user_item_matrix.index:
            return self.user_mean_ratings.mean()  # è¿”å›å…¨å±€å¹³å‡åˆ†
        
        if item_id not in self.user_item_matrix.columns:
            return self.user_mean_ratings[user_id]  # è¿”å›ç”¨æˆ·å¹³å‡åˆ†
        
        # å¦‚æœç”¨æˆ·å·²ç»è¯„åˆ†è¿‡è¯¥ç‰©å“ | If user has already rated this item
        if self.user_item_matrix.loc[user_id, item_id] != 0:
            return self.user_item_matrix.loc[user_id, item_id]
        
        # æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ· | Find similar users
        user_similarities = self.user_similarity_matrix.loc[user_id]
        
        # æ‰¾åˆ°è¯„åˆ†è¿‡è¯¥ç‰©å“çš„ç”¨æˆ· | Find users who rated this item
        item_raters = self.user_item_matrix[self.user_item_matrix[item_id] != 0].index
        
        # è®¡ç®—ç›¸ä¼¼ç”¨æˆ·å¯¹è¯¥ç‰©å“çš„è¯„åˆ† | Calculate similar users' ratings for this item
        similar_users = user_similarities[item_raters]
        
        # é€‰æ‹©æœ€ç›¸ä¼¼çš„Kä¸ªç”¨æˆ· | Select top-K similar users
        top_similar_users = similar_users.nlargest(self.n_neighbors)
        
        if len(top_similar_users) == 0:
            return self.user_mean_ratings[user_id]
        
        # è®¡ç®—åŠ æƒå¹³å‡è¯„åˆ† | Calculate weighted average rating
        numerator = 0
        denominator = 0
        
        for similar_user, similarity in top_similar_users.items():
            if similarity > 0:  # åªè€ƒè™‘æ­£ç›¸å…³çš„ç”¨æˆ·
                rating = self.user_item_matrix.loc[similar_user, item_id]
                user_mean = self.user_mean_ratings[similar_user]
                
                # ä½¿ç”¨ä¸­å¿ƒåŒ–è¯„åˆ† | Use centered ratings
                numerator += similarity * (rating - user_mean)
                denominator += abs(similarity)
        
        if denominator == 0:
            return self.user_mean_ratings[user_id]
        
        # é¢„æµ‹è¯„åˆ† = ç”¨æˆ·å¹³å‡åˆ† + åŠ æƒå¹³å‡åå·®
        # Predicted rating = user mean + weighted average deviation
        predicted_rating = self.user_mean_ratings[user_id] + (numerator / denominator)
        
        # é™åˆ¶è¯„åˆ†èŒƒå›´ | Constrain rating range
        return max(1, min(5, predicted_rating))
    
    def recommend_items(self, user_id, n_recommendations=10):
        """
        ä¸ºç”¨æˆ·æ¨èç‰©å“
        Recommend items for a user
        """
        if user_id not in self.user_item_matrix.index:
            print(f"ç”¨æˆ· {user_id} ä¸å­˜åœ¨äºè®­ç»ƒæ•°æ®ä¸­")
            print(f"User {user_id} not found in training data")
            return []
        
        # æ‰¾åˆ°ç”¨æˆ·æœªè¯„åˆ†çš„ç‰©å“ | Find items not rated by the user
        user_ratings = self.user_item_matrix.loc[user_id]
        unrated_items = user_ratings[user_ratings == 0].index
        
        # é¢„æµ‹æ‰€æœ‰æœªè¯„åˆ†ç‰©å“çš„è¯„åˆ† | Predict ratings for all unrated items
        predictions = []
        for item_id in unrated_items:
            predicted_rating = self.predict_rating(user_id, item_id)
            predictions.append((item_id, predicted_rating))
        
        # æŒ‰é¢„æµ‹è¯„åˆ†æ’åº | Sort by predicted rating
        predictions.sort(key=lambda x: x[1], reverse=True)
        
        # è¿”å›top-Næ¨è | Return top-N recommendations
        return predictions[:n_recommendations]
    
    def evaluate(self, test_df):
        """
        è¯„ä¼°æ¨èç³»ç»Ÿæ€§èƒ½
        Evaluate recommender system performance
        """
        print("è¯„ä¼°æ¨èç³»ç»Ÿæ€§èƒ½...")
        print("Evaluating recommender system performance...")
        
        mae_scores = []  # å¹³å‡ç»å¯¹è¯¯å·® | Mean Absolute Error
        rmse_scores = []  # å‡æ–¹æ ¹è¯¯å·® | Root Mean Squared Error
        
        for _, row in test_df.iterrows():
            user_id = row['user_id']
            item_id = row['item_id']
            true_rating = row['rating']
            
            predicted_rating = self.predict_rating(user_id, item_id)
            
            mae_scores.append(abs(true_rating - predicted_rating))
            rmse_scores.append((true_rating - predicted_rating) ** 2)
        
        mae = np.mean(mae_scores)
        rmse = np.sqrt(np.mean(rmse_scores))
        
        print(f"å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.4f}")
        print(f"å‡æ–¹æ ¹è¯¯å·® (RMSE): {rmse:.4f}")
        print(f"Mean Absolute Error (MAE): {mae:.4f}")
        print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")
        
        return {'MAE': mae, 'RMSE': rmse}
    
    def analyze_user_similarity(self, user_id, top_k=10):
        """
        åˆ†æç”¨æˆ·ç›¸ä¼¼åº¦
        Analyze user similarity
        """
        if user_id not in self.user_similarity_matrix.index:
            print(f"ç”¨æˆ· {user_id} ä¸å­˜åœ¨")
            return
        
        # è·å–æœ€ç›¸ä¼¼çš„ç”¨æˆ· | Get most similar users
        similar_users = self.user_similarity_matrix.loc[user_id].nlargest(top_k + 1)[1:]  # æ’é™¤è‡ªå·±
        
        print(f"ä¸ç”¨æˆ· {user_id} æœ€ç›¸ä¼¼çš„ {top_k} ä¸ªç”¨æˆ·:")
        print(f"Top {top_k} users most similar to user {user_id}:")
        
        for similar_user, similarity in similar_users.items():
            print(f"ç”¨æˆ· {similar_user}: ç›¸ä¼¼åº¦ {similarity:.4f}")
            print(f"User {similar_user}: Similarity {similarity:.4f}")
        
        return similar_users
    
    def visualize_similarity_distribution(self):
        """
        å¯è§†åŒ–ç›¸ä¼¼åº¦åˆ†å¸ƒ
        Visualize similarity distribution
        """
        # æå–ä¸Šä¸‰è§’çŸ©é˜µçš„ç›¸ä¼¼åº¦å€¼ | Extract similarity values from upper triangle
        similarity_values = []
        n_users = len(self.user_similarity_matrix)
        
        for i in range(n_users):
            for j in range(i + 1, n_users):
                similarity_values.append(self.user_similarity_matrix.iloc[i, j])
        
        # ç»˜åˆ¶åˆ†å¸ƒå›¾ | Plot distribution
        plt.figure(figsize=(12, 5))
        
        plt.subplot(1, 2, 1)
        plt.hist(similarity_values, bins=50, alpha=0.7, edgecolor='black')
        plt.title('User Similarity Distribution')
        plt.xlabel('Similarity Score')
        plt.ylabel('Frequency')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(1, 2, 2)
        plt.boxplot(similarity_values)
        plt.title('User Similarity Box Plot')
        plt.ylabel('Similarity Score')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # ç»Ÿè®¡ä¿¡æ¯ | Statistics
        print(f"ç›¸ä¼¼åº¦ç»Ÿè®¡ä¿¡æ¯ | Similarity Statistics:")
        print(f"å¹³å‡å€¼ | Mean: {np.mean(similarity_values):.4f}")
        print(f"æ ‡å‡†å·® | Std: {np.std(similarity_values):.4f}")
        print(f"æœ€å°å€¼ | Min: {np.min(similarity_values):.4f}")
        print(f"æœ€å¤§å€¼ | Max: {np.max(similarity_values):.4f}")
```

#### ç‰©å“ååŒè¿‡æ»¤ | Item-based Collaborative Filtering

**é¡¹ç›®ç‰¹è‰² | Project Features:**
ç‰©å“ååŒè¿‡æ»¤åŸºäº"å–œæ¬¢ç›¸ä¼¼ç‰©å“çš„ç”¨æˆ·"çš„å‡è®¾ï¼Œé€šè¿‡ç‰©å“é—´çš„ç›¸ä¼¼æ€§è¿›è¡Œæ¨èï¼Œå…·æœ‰æ›´å¥½çš„ç¨³å®šæ€§ã€‚

Item-based collaborative filtering is based on the assumption of "users who like similar items", making recommendations through item similarities with better stability.

**ç‰©å“ç›¸ä¼¼åº¦è®¡ç®— | Item Similarity Calculation:**
```python
class ItemBasedCollaborativeFiltering:
    """
    åŸºäºç‰©å“çš„ååŒè¿‡æ»¤æ¨èç³»ç»Ÿ
    Item-based Collaborative Filtering Recommender System
    """
    def __init__(self, n_neighbors=20, similarity_metric='cosine'):
        self.n_neighbors = n_neighbors
        self.similarity_metric = similarity_metric
        self.user_item_matrix = None
        self.item_similarity_matrix = None
        self.item_mean_ratings = None
        
    def fit(self, ratings_df):
        """
        è®­ç»ƒæ¨èæ¨¡å‹
        Train the recommendation model
        """
        print("æ„å»ºç”¨æˆ·-ç‰©å“è¯„åˆ†çŸ©é˜µ...")
        print("Building user-item rating matrix...")
        
        # æ„å»ºç”¨æˆ·-ç‰©å“è¯„åˆ†çŸ©é˜µ | Build user-item rating matrix
        self.user_item_matrix = ratings_df.pivot_table(
            index='user_id', 
            columns='item_id', 
            values='rating',
            fill_value=0
        )
        
        # è®¡ç®—ç‰©å“å¹³å‡è¯„åˆ† | Calculate item mean ratings
        self.item_mean_ratings = self.user_item_matrix.mean(axis=0)
        
        print("è®¡ç®—ç‰©å“ç›¸ä¼¼åº¦çŸ©é˜µ...")
        print("Computing item similarity matrix...")
        
        # è®¡ç®—ç‰©å“ç›¸ä¼¼åº¦çŸ©é˜µï¼ˆè½¬ç½®çŸ©é˜µï¼‰| Compute item similarity matrix (transpose)
        if self.similarity_metric == 'cosine':
            self.item_similarity_matrix = cosine_similarity(self.user_item_matrix.T)
        elif self.similarity_metric == 'pearson':
            self.item_similarity_matrix = self._compute_pearson_similarity()
        
        # è½¬æ¢ä¸ºDataFrame | Convert to DataFrame
        self.item_similarity_matrix = pd.DataFrame(
            self.item_similarity_matrix,
            index=self.user_item_matrix.columns,
            columns=self.user_item_matrix.columns
        )
        
        print("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        print("Model training completed!")
        
        return self
    
    def _compute_pearson_similarity(self):
        """
        è®¡ç®—ç‰©å“é—´çš„çš®å°”é€Šç›¸å…³ç³»æ•°
        Compute Pearson correlation between items
        """
        # è½¬ç½®çŸ©é˜µï¼Œä½¿ç‰©å“æˆä¸ºè¡Œ | Transpose matrix to make items as rows
        item_matrix = self.user_item_matrix.T
        
        # ä¸­å¿ƒåŒ–è¯„åˆ†çŸ©é˜µ | Center the rating matrix
        centered_matrix = item_matrix.sub(self.item_mean_ratings, axis=0)
        
        # è®¡ç®—ç›¸å…³ç³»æ•° | Compute correlation coefficients
        correlation_matrix = np.corrcoef(centered_matrix.fillna(0))
        
        # å¤„ç†NaNå€¼ | Handle NaN values
        correlation_matrix = np.nan_to_num(correlation_matrix)
        
        return correlation_matrix
    
    def predict_rating(self, user_id, item_id):
        """
        é¢„æµ‹ç”¨æˆ·å¯¹ç‰©å“çš„è¯„åˆ†
        Predict user's rating for an item
        """
        if user_id not in self.user_item_matrix.index:
            return self.item_mean_ratings.mean()
        
        if item_id not in self.user_item_matrix.columns:
            return self.user_item_matrix.loc[user_id].mean()
        
        # å¦‚æœç”¨æˆ·å·²ç»è¯„åˆ†è¿‡è¯¥ç‰©å“ | If user has already rated this item
        if self.user_item_matrix.loc[user_id, item_id] != 0:
            return self.user_item_matrix.loc[user_id, item_id]
        
        # è·å–ç”¨æˆ·è¯„åˆ†è¿‡çš„ç‰©å“ | Get items rated by the user
        user_ratings = self.user_item_matrix.loc[user_id]
        rated_items = user_ratings[user_ratings != 0]
        
        if len(rated_items) == 0:
            return self.item_mean_ratings[item_id]
        
        # è·å–ç›®æ ‡ç‰©å“ä¸ç”¨æˆ·è¯„åˆ†ç‰©å“çš„ç›¸ä¼¼åº¦ | Get similarities between target item and user-rated items
        item_similarities = self.item_similarity_matrix.loc[item_id, rated_items.index]
        
        # é€‰æ‹©æœ€ç›¸ä¼¼çš„Kä¸ªç‰©å“ | Select top-K similar items
        top_similar_items = item_similarities.nlargest(self.n_neighbors)
        
        if len(top_similar_items) == 0:
            return self.item_mean_ratings[item_id]
        
        # è®¡ç®—åŠ æƒå¹³å‡è¯„åˆ† | Calculate weighted average rating
        numerator = 0
        denominator = 0
        
        for similar_item, similarity in top_similar_items.items():
            if similarity > 0:  # åªè€ƒè™‘æ­£ç›¸å…³çš„ç‰©å“
                rating = user_ratings[similar_item]
                item_mean = self.item_mean_ratings[similar_item]
                
                # ä½¿ç”¨ä¸­å¿ƒåŒ–è¯„åˆ† | Use centered ratings
                numerator += similarity * (rating - item_mean)
                denominator += abs(similarity)
        
        if denominator == 0:
            return self.item_mean_ratings[item_id]
        
        # é¢„æµ‹è¯„åˆ† = ç‰©å“å¹³å‡åˆ† + åŠ æƒå¹³å‡åå·®
        # Predicted rating = item mean + weighted average deviation
        predicted_rating = self.item_mean_ratings[item_id] + (numerator / denominator)
        
        # é™åˆ¶è¯„åˆ†èŒƒå›´ | Constrain rating range
        return max(1, min(5, predicted_rating))
    
    def recommend_items(self, user_id, n_recommendations=10):
        """
        ä¸ºç”¨æˆ·æ¨èç‰©å“
        Recommend items for a user
        """
        if user_id not in self.user_item_matrix.index:
            print(f"ç”¨æˆ· {user_id} ä¸å­˜åœ¨äºè®­ç»ƒæ•°æ®ä¸­")
            return []
        
        # æ‰¾åˆ°ç”¨æˆ·æœªè¯„åˆ†çš„ç‰©å“ | Find items not rated by the user
        user_ratings = self.user_item_matrix.loc[user_id]
        unrated_items = user_ratings[user_ratings == 0].index
        
        # é¢„æµ‹æ‰€æœ‰æœªè¯„åˆ†ç‰©å“çš„è¯„åˆ† | Predict ratings for all unrated items
        predictions = []
        for item_id in unrated_items:
            predicted_rating = self.predict_rating(user_id, item_id)
            predictions.append((item_id, predicted_rating))
        
        # æŒ‰é¢„æµ‹è¯„åˆ†æ’åº | Sort by predicted rating
        predictions.sort(key=lambda x: x[1], reverse=True)
        
        return predictions[:n_recommendations]
    
    def find_similar_items(self, item_id, n_similar=10):
        """
        æ‰¾åˆ°ä¸æŒ‡å®šç‰©å“ç›¸ä¼¼çš„ç‰©å“
        Find items similar to a specified item
        """
        if item_id not in self.item_similarity_matrix.index:
            print(f"ç‰©å“ {item_id} ä¸å­˜åœ¨")
            return []
        
        # è·å–æœ€ç›¸ä¼¼çš„ç‰©å“ | Get most similar items
        similar_items = self.item_similarity_matrix.loc[item_id].nlargest(n_similar + 1)[1:]  # æ’é™¤è‡ªå·±
        
        return list(similar_items.items())
```

### 02_å†…å®¹æ¨èç³»ç»Ÿ | Content-based Recommendation Systems

**åŸºäºç‰©å“ç‰¹å¾çš„æ™ºèƒ½æ¨èï¼**
**Intelligent recommendations based on item features!**

#### åŸºäºå†…å®¹çš„æ¨è | Content-based Recommendation

**é¡¹ç›®æ ¸å¿ƒ | Project Core:**
å†…å®¹æ¨èé€šè¿‡åˆ†æç‰©å“çš„ç‰¹å¾å’Œç”¨æˆ·çš„åå¥½å†å²ï¼Œä¸ºç”¨æˆ·æ¨èå…·æœ‰ç›¸ä¼¼ç‰¹å¾çš„ç‰©å“ã€‚

Content-based recommendation analyzes item features and user preference history to recommend items with similar characteristics.

**TF-IDFç‰¹å¾æå– | TF-IDF Feature Extraction:**
```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, linear_kernel
import pandas as pd
import numpy as np

class ContentBasedRecommender:
    """
    åŸºäºå†…å®¹çš„æ¨èç³»ç»Ÿ
    Content-based Recommender System
    """
    def __init__(self, content_features=['genre', 'director', 'actors', 'description']):
        self.content_features = content_features
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=10000,
            stop_words='english',
            ngram_range=(1, 2),
            min_df=2,
            max_df=0.8
        )
        self.content_matrix = None
        self.item_features_df = None
        self.user_profiles = {}
        
    def fit(self, items_df, ratings_df):
        """
        è®­ç»ƒå†…å®¹æ¨èæ¨¡å‹
        Train content-based recommendation model
        
        Args:
            items_df: DataFrame with item features
            ratings_df: DataFrame with user ratings
        """
        print("æ„å»ºç‰©å“å†…å®¹ç‰¹å¾çŸ©é˜µ...")
        print("Building item content feature matrix...")
        
        self.item_features_df = items_df.copy()
        
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬ç‰¹å¾ | Combine all text features
        combined_features = []
        for _, item in items_df.iterrows():
            features = []
            for feature in self.content_features:
                if feature in item and pd.notna(item[feature]):
                    if isinstance(item[feature], str):
                        features.append(item[feature])
                    else:
                        features.append(str(item[feature]))
            combined_features.append(' '.join(features))
        
        # ä½¿ç”¨TF-IDFå‘é‡åŒ– | Vectorize using TF-IDF
        self.content_matrix = self.tfidf_vectorizer.fit_transform(combined_features)
        
        print("æ„å»ºç”¨æˆ·åå¥½æ¡£æ¡ˆ...")
        print("Building user preference profiles...")
        
        # æ„å»ºç”¨æˆ·åå¥½æ¡£æ¡ˆ | Build user preference profiles
        self._build_user_profiles(ratings_df)
        
        print("å†…å®¹æ¨èæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        print("Content-based model training completed!")
        
        return self
    
    def _build_user_profiles(self, ratings_df):
        """
        æ„å»ºç”¨æˆ·åå¥½æ¡£æ¡ˆ
        Build user preference profiles
        """
        for user_id in ratings_df['user_id'].unique():
            user_ratings = ratings_df[ratings_df['user_id'] == user_id]
            
            # è®¡ç®—ç”¨æˆ·å¯¹æ¯ä¸ªç‰©å“ç‰¹å¾çš„åå¥½æƒé‡ | Calculate user preference weights for each item feature
            user_profile = np.zeros(self.content_matrix.shape[1])
            total_weight = 0
            
            for _, rating_row in user_ratings.iterrows():
                item_id = rating_row['item_id']
                rating = rating_row['rating']
                
                # æ‰¾åˆ°ç‰©å“åœ¨ç‰¹å¾çŸ©é˜µä¸­çš„ç´¢å¼• | Find item index in feature matrix
                item_idx = self.item_features_df[self.item_features_df['item_id'] == item_id].index
                
                if len(item_idx) > 0:
                    item_idx = item_idx[0]
                    item_features = self.content_matrix[item_idx].toarray().flatten()
                    
                    # ä½¿ç”¨è¯„åˆ†ä½œä¸ºæƒé‡ | Use rating as weight
                    weight = rating - 3  # ä¸­å¿ƒåŒ–è¯„åˆ† (å‡è®¾è¯„åˆ†èŒƒå›´1-5)
                    user_profile += weight * item_features
                    total_weight += abs(weight)
            
            # å½’ä¸€åŒ–ç”¨æˆ·æ¡£æ¡ˆ | Normalize user profile
            if total_weight > 0:
                user_profile = user_profile / total_weight
            
            self.user_profiles[user_id] = user_profile
    
    def predict_rating(self, user_id, item_id):
        """
        é¢„æµ‹ç”¨æˆ·å¯¹ç‰©å“çš„è¯„åˆ†
        Predict user's rating for an item
        """
        if user_id not in self.user_profiles:
            return 3.0  # é»˜è®¤ä¸­æ€§è¯„åˆ†
        
        # æ‰¾åˆ°ç‰©å“ç‰¹å¾ | Find item features
        item_idx = self.item_features_df[self.item_features_df['item_id'] == item_id].index
        
        if len(item_idx) == 0:
            return 3.0
        
        item_idx = item_idx[0]
        item_features = self.content_matrix[item_idx].toarray().flatten()
        user_profile = self.user_profiles[user_id]
        
        # è®¡ç®—ç”¨æˆ·æ¡£æ¡ˆä¸ç‰©å“ç‰¹å¾çš„ç›¸ä¼¼åº¦ | Calculate similarity between user profile and item features
        similarity = np.dot(user_profile, item_features)
        
        # è½¬æ¢ä¸º1-5çš„è¯„åˆ†èŒƒå›´ | Convert to 1-5 rating scale
        predicted_rating = 3 + 2 * similarity  # å‡è®¾ç›¸ä¼¼åº¦åœ¨[-1, 1]èŒƒå›´å†…
        
        return max(1, min(5, predicted_rating))
    
    def recommend_items(self, user_id, n_recommendations=10, exclude_rated=True):
        """
        ä¸ºç”¨æˆ·æ¨èç‰©å“
        Recommend items for a user
        """
        if user_id not in self.user_profiles:
            print(f"ç”¨æˆ· {user_id} æ²¡æœ‰åå¥½æ¡£æ¡ˆ")
            return []
        
        # è®¡ç®—æ‰€æœ‰ç‰©å“çš„é¢„æµ‹è¯„åˆ† | Calculate predicted ratings for all items
        predictions = []
        for idx, item_row in self.item_features_df.iterrows():
            item_id = item_row['item_id']
            predicted_rating = self.predict_rating(user_id, item_id)
            predictions.append((item_id, predicted_rating))
        
        # æŒ‰é¢„æµ‹è¯„åˆ†æ’åº | Sort by predicted rating
        predictions.sort(key=lambda x: x[1], reverse=True)
        
        return predictions[:n_recommendations]
    
    def find_similar_items(self, item_id, n_similar=10):
        """
        æ‰¾åˆ°å†…å®¹ç›¸ä¼¼çš„ç‰©å“
        Find content-similar items
        """
        # æ‰¾åˆ°ç‰©å“ç´¢å¼• | Find item index
        item_idx = self.item_features_df[self.item_features_df['item_id'] == item_id].index
        
        if len(item_idx) == 0:
            print(f"ç‰©å“ {item_id} ä¸å­˜åœ¨")
            return []
        
        item_idx = item_idx[0]
        
        # è®¡ç®—ä¸æ‰€æœ‰ç‰©å“çš„ä½™å¼¦ç›¸ä¼¼åº¦ | Calculate cosine similarity with all items
        similarities = cosine_similarity(
            self.content_matrix[item_idx], 
            self.content_matrix
        ).flatten()
        
        # è·å–æœ€ç›¸ä¼¼çš„ç‰©å“ç´¢å¼• | Get indices of most similar items
        similar_indices = similarities.argsort()[::-1][1:n_similar+1]  # æ’é™¤è‡ªå·±
        
        # è¿”å›ç›¸ä¼¼ç‰©å“å’Œç›¸ä¼¼åº¦ | Return similar items and similarities
        similar_items = []
        for idx in similar_indices:
            similar_item_id = self.item_features_df.iloc[idx]['item_id']
            similarity_score = similarities[idx]
            similar_items.append((similar_item_id, similarity_score))
        
        return similar_items
    
    def analyze_user_preferences(self, user_id, top_features=10):
        """
        åˆ†æç”¨æˆ·åå¥½ç‰¹å¾
        Analyze user preference features
        """
        if user_id not in self.user_profiles:
            print(f"ç”¨æˆ· {user_id} æ²¡æœ‰åå¥½æ¡£æ¡ˆ")
            return
        
        user_profile = self.user_profiles[user_id]
        feature_names = self.tfidf_vectorizer.get_feature_names_out()
        
        # è·å–æƒé‡æœ€é«˜çš„ç‰¹å¾ | Get features with highest weights
        top_feature_indices = user_profile.argsort()[::-1][:top_features]
        
        print(f"ç”¨æˆ· {user_id} çš„åå¥½ç‰¹å¾:")
        print(f"User {user_id}'s preference features:")
        
        for i, feature_idx in enumerate(top_feature_indices):
            feature_name = feature_names[feature_idx]
            weight = user_profile[feature_idx]
            print(f"{i+1}. {feature_name}: {weight:.4f}")
```

#### æ··åˆæ¨èç³»ç»Ÿ | Hybrid Recommendation System

**é¡¹ç›®ä»·å€¼ | Project Value:**
æ··åˆæ¨èç³»ç»Ÿç»“åˆå¤šç§æ¨èæŠ€æœ¯çš„ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿæä¾›æ›´å‡†ç¡®å’Œå¤šæ ·åŒ–çš„æ¨èã€‚

Hybrid recommendation systems combine the advantages of multiple recommendation techniques to provide more accurate and diverse recommendations.

**çº¿æ€§ç»„åˆæ··åˆæ–¹æ³• | Linear Combination Hybrid Method:**
```python
class HybridRecommender:
    """
    æ··åˆæ¨èç³»ç»Ÿ
    Hybrid Recommender System
    """
    def __init__(self, cf_weight=0.4, content_weight=0.4, popularity_weight=0.2):
        self.cf_weight = cf_weight
        self.content_weight = content_weight
        self.popularity_weight = popularity_weight
        
        # å„ä¸ªæ¨èç»„ä»¶ | Individual recommendation components
        self.cf_recommender = None
        self.content_recommender = None
        self.popularity_scores = None
        
    def fit(self, ratings_df, items_df):
        """
        è®­ç»ƒæ··åˆæ¨èç³»ç»Ÿ
        Train hybrid recommendation system
        """
        print("è®­ç»ƒååŒè¿‡æ»¤ç»„ä»¶...")
        print("Training collaborative filtering component...")
        
        # è®­ç»ƒååŒè¿‡æ»¤æ¨èå™¨ | Train collaborative filtering recommender
        self.cf_recommender = ItemBasedCollaborativeFiltering()
        self.cf_recommender.fit(ratings_df)
        
        print("è®­ç»ƒå†…å®¹æ¨èç»„ä»¶...")
        print("Training content-based component...")
        
        # è®­ç»ƒå†…å®¹æ¨èå™¨ | Train content-based recommender
        self.content_recommender = ContentBasedRecommender()
        self.content_recommender.fit(items_df, ratings_df)
        
        print("è®¡ç®—ç‰©å“æµè¡Œåº¦...")
        print("Computing item popularity...")
        
        # è®¡ç®—ç‰©å“æµè¡Œåº¦åˆ†æ•° | Compute item popularity scores
        item_popularity = ratings_df['item_id'].value_counts()
        max_popularity = item_popularity.max()
        self.popularity_scores = (item_popularity / max_popularity).to_dict()
        
        print("æ··åˆæ¨èç³»ç»Ÿè®­ç»ƒå®Œæˆï¼")
        print("Hybrid recommendation system training completed!")
        
        return self
    
    def predict_rating(self, user_id, item_id):
        """
        é¢„æµ‹è¯„åˆ†ï¼ˆæ··åˆå¤šç§æ–¹æ³•ï¼‰
        Predict rating (hybrid of multiple methods)
        """
        # ååŒè¿‡æ»¤é¢„æµ‹ | Collaborative filtering prediction
        cf_rating = self.cf_recommender.predict_rating(user_id, item_id)
        
        # å†…å®¹æ¨èé¢„æµ‹ | Content-based prediction
        content_rating = self.content_recommender.predict_rating(user_id, item_id)
        
        # æµè¡Œåº¦åˆ†æ•° | Popularity score
        popularity_score = self.popularity_scores.get(item_id, 0)
        popularity_rating = 1 + 4 * popularity_score  # è½¬æ¢ä¸º1-5åˆ†
        
        # çº¿æ€§ç»„åˆ | Linear combination
        hybrid_rating = (
            self.cf_weight * cf_rating +
            self.content_weight * content_rating +
            self.popularity_weight * popularity_rating
        )
        
        return max(1, min(5, hybrid_rating))
    
    def recommend_items(self, user_id, n_recommendations=10):
        """
        æ··åˆæ¨è
        Hybrid recommendation
        """
        # è·å–å„ç§æ¨èæ–¹æ³•çš„ç»“æœ | Get results from different recommendation methods
        cf_recommendations = self.cf_recommender.recommend_items(user_id, n_recommendations * 2)
        content_recommendations = self.content_recommender.recommend_items(user_id, n_recommendations * 2)
        
        # åˆå¹¶æ¨èç»“æœ | Combine recommendation results
        all_items = set()
        for item_id, _ in cf_recommendations:
            all_items.add(item_id)
        for item_id, _ in content_recommendations:
            all_items.add(item_id)
        
        # è®¡ç®—æ··åˆè¯„åˆ† | Calculate hybrid scores
        hybrid_recommendations = []
        for item_id in all_items:
            hybrid_rating = self.predict_rating(user_id, item_id)
            hybrid_recommendations.append((item_id, hybrid_rating))
        
        # æŒ‰æ··åˆè¯„åˆ†æ’åº | Sort by hybrid scores
        hybrid_recommendations.sort(key=lambda x: x[1], reverse=True)
        
        return hybrid_recommendations[:n_recommendations]
    
    def evaluate_components(self, test_df):
        """
        è¯„ä¼°å„ä¸ªç»„ä»¶çš„æ€§èƒ½
        Evaluate performance of individual components
        """
        print("è¯„ä¼°å„ä¸ªæ¨èç»„ä»¶çš„æ€§èƒ½...")
        print("Evaluating performance of individual recommendation components...")
        
        # è¯„ä¼°ååŒè¿‡æ»¤ | Evaluate collaborative filtering
        cf_mae, cf_rmse = self._evaluate_single_component(test_df, 'cf')
        
        # è¯„ä¼°å†…å®¹æ¨è | Evaluate content-based
        content_mae, content_rmse = self._evaluate_single_component(test_df, 'content')
        
        # è¯„ä¼°æ··åˆç³»ç»Ÿ | Evaluate hybrid system
        hybrid_mae, hybrid_rmse = self._evaluate_single_component(test_df, 'hybrid')
        
        # æ‰“å°ç»“æœ | Print results
        print(f"\næ€§èƒ½å¯¹æ¯” | Performance Comparison:")
        print(f"ååŒè¿‡æ»¤ CF - MAE: {cf_mae:.4f}, RMSE: {cf_rmse:.4f}")
        print(f"å†…å®¹æ¨è Content - MAE: {content_mae:.4f}, RMSE: {content_rmse:.4f}")
        print(f"æ··åˆç³»ç»Ÿ Hybrid - MAE: {hybrid_mae:.4f}, RMSE: {hybrid_rmse:.4f}")
        
        return {
            'CF': {'MAE': cf_mae, 'RMSE': cf_rmse},
            'Content': {'MAE': content_mae, 'RMSE': content_rmse},
            'Hybrid': {'MAE': hybrid_mae, 'RMSE': hybrid_rmse}
        }
    
    def _evaluate_single_component(self, test_df, component_type):
        """
        è¯„ä¼°å•ä¸ªç»„ä»¶
        Evaluate single component
        """
        mae_scores = []
        rmse_scores = []
        
        for _, row in test_df.iterrows():
            user_id = row['user_id']
            item_id = row['item_id']
            true_rating = row['rating']
            
            if component_type == 'cf':
                predicted_rating = self.cf_recommender.predict_rating(user_id, item_id)
            elif component_type == 'content':
                predicted_rating = self.content_recommender.predict_rating(user_id, item_id)
            else:  # hybrid
                predicted_rating = self.predict_rating(user_id, item_id)
            
            mae_scores.append(abs(true_rating - predicted_rating))
            rmse_scores.append((true_rating - predicted_rating) ** 2)
        
        mae = np.mean(mae_scores)
        rmse = np.sqrt(np.mean(rmse_scores))
        
        return mae, rmse
```

### 03_æ·±åº¦å­¦ä¹ æ¨è | Deep Learning Recommendations

**ç”¨ç¥ç»ç½‘ç»œé‡æ–°å®šä¹‰æ¨èç³»ç»Ÿï¼**
**Redefine recommendation systems with neural networks!**

#### ç¥ç»ååŒè¿‡æ»¤ | Neural Collaborative Filtering

**é¡¹ç›®çªç ´ | Project Breakthrough:**
ç¥ç»ååŒè¿‡æ»¤ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œæ›¿ä»£ä¼ ç»Ÿçš„çŸ©é˜µåˆ†è§£ï¼Œèƒ½å¤Ÿæ•æ‰æ›´å¤æ‚çš„ç”¨æˆ·-ç‰©å“äº¤äº’æ¨¡å¼ã€‚

Neural Collaborative Filtering uses deep neural networks to replace traditional matrix factorization, capable of capturing more complex user-item interaction patterns.

**NCFæ¨¡å‹å®ç° | NCF Model Implementation:**
```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F

class NCFDataset(Dataset):
    """
    ç¥ç»ååŒè¿‡æ»¤æ•°æ®é›†
    Neural Collaborative Filtering Dataset
    """
    def __init__(self, ratings_df, num_negatives=4):
        self.ratings_df = ratings_df
        self.num_negatives = num_negatives
        
        # æ„å»ºç”¨æˆ·å’Œç‰©å“çš„æ˜ å°„ | Build user and item mappings
        self.user_to_idx = {user: idx for idx, user in enumerate(ratings_df['user_id'].unique())}
        self.item_to_idx = {item: idx for idx, item in enumerate(ratings_df['item_id'].unique())}
        
        self.num_users = len(self.user_to_idx)
        self.num_items = len(self.item_to_idx)
        
        # æ„å»ºæ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬ | Build positive and negative samples
        self.samples = self._build_samples()
    
    def _build_samples(self):
        """
        æ„å»ºè®­ç»ƒæ ·æœ¬ï¼ˆæ­£æ ·æœ¬+è´Ÿæ ·æœ¬ï¼‰
        Build training samples (positive + negative)
        """
        samples = []
        
        # æ„å»ºç”¨æˆ·çš„æ­£æ ·æœ¬é›†åˆ | Build positive item sets for users
        user_items = self.ratings_df.groupby('user_id')['item_id'].apply(set).to_dict()
        all_items = set(self.item_to_idx.keys())
        
        for _, row in self.ratings_df.iterrows():
            user_id = row['user_id']
            item_id = row['item_id']
            rating = row['rating']
            
            user_idx = self.user_to_idx[user_id]
            item_idx = self.item_to_idx[item_id]
            
            # æ­£æ ·æœ¬ | Positive sample
            samples.append((user_idx, item_idx, 1.0))
            
            # è´Ÿé‡‡æ · | Negative sampling
            user_positive_items = user_items[user_id]
            negative_items = all_items - user_positive_items
            
            negative_samples = np.random.choice(
                list(negative_items), 
                size=min(self.num_negatives, len(negative_items)), 
                replace=False
            )
            
            for neg_item in negative_samples:
                neg_item_idx = self.item_to_idx[neg_item]
                samples.append((user_idx, neg_item_idx, 0.0))
        
        return samples
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        user_idx, item_idx, label = self.samples[idx]
        return torch.LongTensor([user_idx]), torch.LongTensor([item_idx]), torch.FloatTensor([label])

class NeuralCollaborativeFiltering(nn.Module):
    """
    ç¥ç»ååŒè¿‡æ»¤æ¨¡å‹
    Neural Collaborative Filtering Model
    """
    def __init__(self, num_users, num_items, embedding_dim=64, hidden_dims=[128, 64]):
        super(NeuralCollaborativeFiltering, self).__init__()
        
        self.num_users = num_users
        self.num_items = num_items
        self.embedding_dim = embedding_dim
        
        # ç”¨æˆ·å’Œç‰©å“åµŒå…¥å±‚ | User and item embedding layers
        self.user_embedding = nn.Embedding(num_users, embedding_dim)
        self.item_embedding = nn.Embedding(num_items, embedding_dim)
        
        # MLPå±‚ | MLP layers
        layers = []
        input_dim = embedding_dim * 2  # ç”¨æˆ·å’Œç‰©å“åµŒå…¥æ‹¼æ¥
        
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(input_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.2)
            ])
            input_dim = hidden_dim
        
        # è¾“å‡ºå±‚ | Output layer
        layers.append(nn.Linear(input_dim, 1))
        layers.append(nn.Sigmoid())
        
        self.mlp = nn.Sequential(*layers)
        
        # æƒé‡åˆå§‹åŒ– | Weight initialization
        self._init_weights()
    
    def _init_weights(self):
        """
        åˆå§‹åŒ–æƒé‡
        Initialize weights
        """
        nn.init.normal_(self.user_embedding.weight, std=0.01)
        nn.init.normal_(self.item_embedding.weight, std=0.01)
        
        for layer in self.mlp:
            if isinstance(layer, nn.Linear):
                nn.init.xavier_normal_(layer.weight)
                nn.init.zeros_(layer.bias)
    
    def forward(self, user_idx, item_idx):
        """
        å‰å‘ä¼ æ’­
        Forward pass
        """
        # è·å–åµŒå…¥å‘é‡ | Get embedding vectors
        user_emb = self.user_embedding(user_idx.squeeze())
        item_emb = self.item_embedding(item_idx.squeeze())
        
        # æ‹¼æ¥ç”¨æˆ·å’Œç‰©å“åµŒå…¥ | Concatenate user and item embeddings
        concat_emb = torch.cat([user_emb, item_emb], dim=-1)
        
        # é€šè¿‡MLPå¾—åˆ°é¢„æµ‹åˆ†æ•° | Get prediction score through MLP
        output = self.mlp(concat_emb)
        
        return output.squeeze()

class NCFRecommender:
    """
    ç¥ç»ååŒè¿‡æ»¤æ¨èå™¨
    Neural Collaborative Filtering Recommender
    """
    def __init__(self, embedding_dim=64, hidden_dims=[128, 64], learning_rate=0.001):
        self.embedding_dim = embedding_dim
        self.hidden_dims = hidden_dims
        self.learning_rate = learning_rate
        
        self.model = None
        self.user_to_idx = None
        self.item_to_idx = None
        self.idx_to_user = None
        self.idx_to_item = None
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
    def fit(self, ratings_df, epochs=50, batch_size=256):
        """
        è®­ç»ƒç¥ç»ååŒè¿‡æ»¤æ¨¡å‹
        Train Neural Collaborative Filtering model
        """
        print("å‡†å¤‡è®­ç»ƒæ•°æ®...")
        print("Preparing training data...")
        
        # åˆ›å»ºæ•°æ®é›† | Create dataset
        dataset = NCFDataset(ratings_df)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
        
        # ä¿å­˜æ˜ å°„å…³ç³» | Save mappings
        self.user_to_idx = dataset.user_to_idx
        self.item_to_idx = dataset.item_to_idx
        self.idx_to_user = {idx: user for user, idx in self.user_to_idx.items()}
        self.idx_to_item = {idx: item for item, idx in self.item_to_idx.items()}
        
        # åˆ›å»ºæ¨¡å‹ | Create model
        self.model = NeuralCollaborativeFiltering(
            num_users=dataset.num_users,
            num_items=dataset.num_items,
            embedding_dim=self.embedding_dim,
            hidden_dims=self.hidden_dims
        ).to(self.device)
        
        # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•° | Optimizer and loss function
        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)
        criterion = nn.BCELoss()
        
        print("å¼€å§‹è®­ç»ƒç¥ç»ååŒè¿‡æ»¤æ¨¡å‹...")
        print("Starting Neural Collaborative Filtering training...")
        
        # è®­ç»ƒå¾ªç¯ | Training loop
        self.model.train()
        for epoch in range(epochs):
            total_loss = 0
            num_batches = 0
            
            for batch_user, batch_item, batch_label in dataloader:
                batch_user = batch_user.to(self.device)
                batch_item = batch_item.to(self.device)
                batch_label = batch_label.to(self.device)
                
                # å‰å‘ä¼ æ’­ | Forward pass
                predictions = self.model(batch_user, batch_item)
                loss = criterion(predictions, batch_label.squeeze())
                
                # åå‘ä¼ æ’­ | Backward pass
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                num_batches += 1
            
            avg_loss = total_loss / num_batches
            if (epoch + 1) % 10 == 0:
                print(f'Epoch {epoch + 1}/{epochs}, Average Loss: {avg_loss:.4f}')
        
        print("NCFæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        print("NCF model training completed!")
        
        return self
    
    def predict_rating(self, user_id, item_id):
        """
        é¢„æµ‹ç”¨æˆ·å¯¹ç‰©å“çš„è¯„åˆ†
        Predict user's rating for an item
        """
        if user_id not in self.user_to_idx or item_id not in self.item_to_idx:
            return 3.0  # é»˜è®¤è¯„åˆ†
        
        self.model.eval()
        with torch.no_grad():
            user_idx = torch.LongTensor([self.user_to_idx[user_id]]).to(self.device)
            item_idx = torch.LongTensor([self.item_to_idx[item_id]]).to(self.device)
            
            prediction = self.model(user_idx, item_idx)
            
            # è½¬æ¢ä¸º1-5çš„è¯„åˆ†èŒƒå›´ | Convert to 1-5 rating scale
            rating = 1 + 4 * prediction.item()
            
        return rating
    
    def recommend_items(self, user_id, n_recommendations=10):
        """
        ä¸ºç”¨æˆ·æ¨èç‰©å“
        Recommend items for a user
        """
        if user_id not in self.user_to_idx:
            print(f"ç”¨æˆ· {user_id} ä¸å­˜åœ¨")
            return []
        
        self.model.eval()
        recommendations = []
        
        with torch.no_grad():
            user_idx = torch.LongTensor([self.user_to_idx[user_id]]).to(self.device)
            
            # å¯¹æ‰€æœ‰ç‰©å“è¿›è¡Œé¢„æµ‹ | Predict for all items
            for item_id, item_idx_val in self.item_to_idx.items():
                item_idx = torch.LongTensor([item_idx_val]).to(self.device)
                prediction = self.model(user_idx, item_idx)
                rating = 1 + 4 * prediction.item()
                recommendations.append((item_id, rating))
        
        # æŒ‰é¢„æµ‹è¯„åˆ†æ’åº | Sort by predicted rating
        recommendations.sort(key=lambda x: x[1], reverse=True)
        
        return recommendations[:n_recommendations]
```

---

**ğŸ¯ é¡¹ç›®å®Œæˆæ£€æŸ¥æ¸…å• | Project Completion Checklist:**

### ç®—æ³•ç†è§£ | Algorithm Understanding
- [ ] æ·±å…¥ç†è§£ååŒè¿‡æ»¤çš„æ•°å­¦åŸç†å’Œå‡è®¾
- [ ] æŒæ¡å†…å®¹æ¨èçš„ç‰¹å¾å·¥ç¨‹å’Œç›¸ä¼¼åº¦è®¡ç®—
- [ ] ç†è§£æ·±åº¦å­¦ä¹ æ¨èçš„ç½‘ç»œæ¶æ„è®¾è®¡
- [ ] èƒ½å¤Ÿåˆ†æä¸åŒæ¨èç®—æ³•çš„ä¼˜åŠ£å’Œé€‚ç”¨åœºæ™¯

### ç³»ç»Ÿå®ç° | System Implementation
- [ ] ä»é›¶å®ç°ç”¨æˆ·å’Œç‰©å“ååŒè¿‡æ»¤ç®—æ³•
- [ ] æ„å»ºå®Œæ•´çš„å†…å®¹æ¨èå’Œæ··åˆæ¨èç³»ç»Ÿ
- [ ] å®ç°ç¥ç»ååŒè¿‡æ»¤ç­‰æ·±åº¦å­¦ä¹ æ¨èæ¨¡å‹
- [ ] æŒæ¡æ¨èç³»ç»Ÿçš„è¯„ä¼°æŒ‡æ ‡å’Œæ–¹æ³•

### å®é™…åº”ç”¨ | Practical Applications
- [ ] åœ¨çœŸå®æ•°æ®é›†ä¸Šè·å¾—è‰¯å¥½çš„æ¨èæ•ˆæœ
- [ ] èƒ½å¤Ÿå¤„ç†å†·å¯åŠ¨ã€æ•°æ®ç¨€ç–ç­‰å®é™…é—®é¢˜
- [ ] æ„å»ºå¯æ‰©å±•çš„æ¨èæœåŠ¡æ¶æ„
- [ ] åˆ†ææ¨èç»“æœçš„å¤šæ ·æ€§å’Œæ–°é¢–æ€§

**è®°ä½**: æ¨èç³»ç»Ÿæ˜¯è¿æ¥ç”¨æˆ·ä¸å†…å®¹çš„æ™ºèƒ½æ¡¥æ¢ã€‚é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œä½ å°†æŒæ¡æ„å»ºä¸ªæ€§åŒ–æ¨èç³»ç»Ÿçš„å®Œæ•´æŠ€æœ¯æ ˆï¼Œä»ç»å…¸ç®—æ³•åˆ°æ·±åº¦å­¦ä¹ çš„å‰æ²¿æ–¹æ³•ï¼

**Remember**: Recommender systems are intelligent bridges connecting users with content. Through this project, you will master the complete technology stack for building personalized recommendation systems, from classic algorithms to cutting-edge deep learning methods! 
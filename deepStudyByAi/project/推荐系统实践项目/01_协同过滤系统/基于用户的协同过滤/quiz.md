# åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤æµ‹è¯•é¢˜ | User-based Collaborative Filtering Quiz

## ğŸ“š æ¦‚å¿µç†è§£ | Concept Understanding

1. **ä»€ä¹ˆæ˜¯"å†·å¯åŠ¨é—®é¢˜"ï¼Ÿç”¨æˆ·ååŒè¿‡æ»¤å¦‚ä½•å—æ­¤å½±å“ï¼Ÿ**
   **What is the "cold start problem"? How does user-based collaborative filtering suffer from it?**
   
   **ç­”æ¡ˆï¼š** å†·å¯åŠ¨é—®é¢˜æ˜¯æŒ‡æ–°ç”¨æˆ·æˆ–æ–°ç‰©å“åŠ å…¥ç³»ç»Ÿæ—¶ï¼Œç”±äºç¼ºä¹è¶³å¤Ÿçš„å†å²è¡Œä¸ºæ•°æ®ï¼Œæ¨èç³»ç»Ÿæ— æ³•åšå‡ºæœ‰æ•ˆæ¨èçš„é—®é¢˜ã€‚å¯¹äºç”¨æˆ·ååŒè¿‡æ»¤ï¼Œæ–°ç”¨æˆ·æ²¡æœ‰è¯„åˆ†è®°å½•ï¼Œç³»ç»Ÿæ— æ³•è®¡ç®—ä»–ä¸å…¶ä»–ç”¨æˆ·çš„ç›¸ä¼¼åº¦ï¼Œå› æ­¤æ— æ³•æ‰¾åˆ°"ç›¸ä¼¼ç”¨æˆ·"æ¥è¿›è¡Œæ¨èã€‚
   **Answer:** The cold start problem refers to the issue where, when new users or items join the system, the recommendation system cannot make effective recommendations due to lack of sufficient historical behavior data. For user-based collaborative filtering, new users have no rating records, so the system cannot calculate their similarity with other users, thus unable to find "similar users" to make recommendations.

2. **ä¸ºä»€ä¹ˆè¦å¯¹ç”¨æˆ·è¯„åˆ†è¿›è¡Œä¸­å¿ƒåŒ–å¤„ç†ï¼ˆå‡å»å¹³å‡åˆ†ï¼‰ï¼Ÿ**
   **Why do we need to center user ratings (subtract the mean)?**
   
   **ç­”æ¡ˆï¼š** ä¸­å¿ƒåŒ–å¤„ç†æ˜¯ä¸ºäº†æ¶ˆé™¤ç”¨æˆ·çš„è¯„åˆ†åè§ã€‚æœ‰äº›ç”¨æˆ·ä¹ æƒ¯æ€§ç»™é«˜åˆ†ï¼ˆæ¯”å¦‚æ€»æ˜¯æ‰“4-5åˆ†ï¼‰ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º"å®½æ¾å‹è¯„åˆ†è€…"ï¼›æœ‰äº›ç”¨æˆ·åˆ™å¾ˆä¸¥æ ¼ï¼ˆç»å¸¸æ‰“1-2åˆ†ï¼‰ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º"ä¸¥æ ¼å‹è¯„åˆ†è€…"ã€‚é€šè¿‡å‡å»å¹³å‡åˆ†ï¼Œæˆ‘ä»¬å¯ä»¥å…³æ³¨ç”¨æˆ·ç›¸å¯¹äºè‡ªå·±æ ‡å‡†çš„åå¥½ï¼Œè€Œä¸æ˜¯ç»å¯¹è¯„åˆ†å€¼ï¼Œä»è€Œä½¿ç›¸ä¼¼åº¦è®¡ç®—æ›´åŠ å‡†ç¡®ã€‚
   **Answer:** Centering is to eliminate user rating bias. Some users habitually give high scores (e.g., always giving 4-5 stars), we call them "lenient raters"; some users are very strict (often giving 1-2 stars), we call them "strict raters". By subtracting the mean, we can focus on the user's preference relative to their own standard, rather than the absolute rating value, thus making similarity calculation more accurate.

3. **ä½™å¼¦ç›¸ä¼¼åº¦å’Œçš®å°”é€Šç›¸å…³ç³»æ•°æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿåœ¨ä»€ä¹ˆåœºæ™¯ä¸‹åº”è¯¥ä½¿ç”¨å“ªç§ï¼Ÿ**
   **What's the difference between cosine similarity and Pearson correlation coefficient? In what scenarios should each be used?**
   
   **ç­”æ¡ˆï¼š** ä½™å¼¦ç›¸ä¼¼åº¦è¡¡é‡çš„æ˜¯ä¸¤ä¸ªå‘é‡æ–¹å‘çš„ç›¸ä¼¼æ€§ï¼Œè€Œçš®å°”é€Šç›¸å…³ç³»æ•°è¡¡é‡çš„æ˜¯ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„çº¿æ€§ç›¸å…³æ€§ã€‚ä¸»è¦åŒºåˆ«åœ¨äºï¼š
   **Answer:** Cosine similarity measures the similarity of direction between two vectors, while Pearson correlation coefficient measures the linear correlation between two variables. The main differences are:
   - ä½™å¼¦ç›¸ä¼¼åº¦å¯¹å‘é‡çš„å¹³ç§»ä¸æ•æ„Ÿ
     Cosine similarity is insensitive to vector translation
   - çš®å°”é€Šç›¸å…³ç³»æ•°ç›¸å½“äºå¯¹å‘é‡è¿›è¡Œä¸­å¿ƒåŒ–åçš„ä½™å¼¦ç›¸ä¼¼åº¦
     Pearson correlation coefficient is equivalent to cosine similarity after vector centering
   
   é€šå¸¸ï¼Œå½“æ•°æ®ç¨€ç–æ—¶ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œå½“éœ€è¦æ¶ˆé™¤ç”¨æˆ·è¯„åˆ†åè§æ—¶ä½¿ç”¨çš®å°”é€Šç›¸å…³ç³»æ•°ã€‚
   Usually, use cosine similarity when data is sparse, and use Pearson correlation coefficient when need to eliminate user rating bias.

## ğŸ§® ç®—æ³•åº”ç”¨ | Algorithm Application

4. **å¦‚æœç”¨æˆ·Aå’Œç”¨æˆ·Bçš„çš®å°”é€Šç›¸å…³ç³»æ•°æ˜¯0.8ï¼Œè¿™è¯´æ˜ä»€ä¹ˆï¼Ÿ**
   **If the Pearson correlation coefficient between user A and user B is 0.8, what does this indicate?**
   
   **ç­”æ¡ˆï¼š** çš®å°”é€Šç›¸å…³ç³»æ•°åœ¨-1åˆ°1ä¹‹é—´ï¼Œå€¼è¶Šæ¥è¿‘1è¡¨ç¤ºæ­£ç›¸å…³æ€§è¶Šå¼ºã€‚0.8çš„ç›¸å…³ç³»æ•°è¡¨æ˜ç”¨æˆ·Aå’Œç”¨æˆ·Bæœ‰å¾ˆå¼ºçš„æ­£ç›¸å…³æ€§ï¼Œå³ä»–ä»¬å€¾å‘äºä»¥ç›¸ä¼¼çš„æ–¹å¼ç»™ç‰©å“è¯„åˆ†ã€‚å½“Aç»™æŸä¸ªç‰©å“é«˜åˆ†æ—¶ï¼ŒBä¹Ÿå¾ˆå¯èƒ½ç»™é«˜åˆ†ï¼›å½“Aç»™ä½åˆ†æ—¶ï¼ŒBä¹Ÿå€¾å‘äºç»™ä½åˆ†ã€‚
   **Answer:** The Pearson correlation coefficient ranges from -1 to 1, with values closer to 1 indicating stronger positive correlation. A correlation coefficient of 0.8 indicates a strong positive correlation between users A and B, meaning they tend to rate items in a similar manner. When A gives a high score to an item, B is also likely to give a high score; when A gives a low score, B tends to give a low score as well.

5. **åœ¨è¯„åˆ†é¢„æµ‹å…¬å¼ä¸­ï¼Œåˆ†æ¯ä¸ºä»€ä¹ˆè¦å–ç›¸ä¼¼åº¦çš„ç»å¯¹å€¼ä¹‹å’Œï¼Ÿ**
   **In the rating prediction formula, why do we take the sum of absolute values of similarities in the denominator?**
   
   **ç­”æ¡ˆï¼š** å› ä¸ºç›¸ä¼¼åº¦å¯èƒ½æ˜¯è´Ÿå€¼ï¼ˆè¡¨ç¤ºç”¨æˆ·å“å‘³ç›¸åï¼‰ï¼Œå¦‚æœç›´æ¥æ±‚å’Œï¼Œæ­£è´Ÿç›¸ä¼¼åº¦å¯èƒ½ä¼šç›¸äº’æŠµæ¶ˆï¼Œå¯¼è‡´åˆ†æ¯æ¥è¿‘0ï¼Œé€ æˆæ•°å€¼ä¸ç¨³å®šã€‚å–ç»å¯¹å€¼ä¹‹å’Œå¯ä»¥ç¡®ä¿åˆ†æ¯å§‹ç»ˆä¸ºæ­£æ•°ï¼Œä½¿åŠ æƒå¹³å‡æ›´åŠ ç¨³å®šå¯é ã€‚
   **Answer:** Because similarity can be negative (indicating opposite user tastes), if we sum directly, positive and negative similarities might cancel each other out, causing the denominator to approach 0 and creating numerical instability. Taking the sum of absolute values ensures the denominator is always positive, making the weighted average more stable and reliable.

## ğŸ“Š å®è·µåˆ†æ | Practical Analysis

6. **å‡è®¾åœ¨ä¸€ä¸ªç”µå½±æ¨èç³»ç»Ÿä¸­ï¼Œä¸¤ä¸ªç”¨æˆ·éƒ½åªè¯„ä»·äº†åŒä¸€éƒ¨ç”µå½±ã€Šé˜¿å‡¡è¾¾ã€‹ï¼Œå¹¶ä¸”éƒ½ç»™äº†5æ˜Ÿã€‚ä»–ä»¬çš„ç›¸ä¼¼åº¦åº”è¯¥æ˜¯å¤šå°‘ï¼Ÿè¿™ç§æƒ…å†µä¸‹ä¼šæœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ**
   **Assume in a movie recommendation system, two users have only rated the same movie 'Avatar' and both gave it 5 stars. What should their similarity be? What problems might arise in this case?**
   
   **ç­”æ¡ˆï¼š** æ ¹æ®çš®å°”é€Šç›¸å…³ç³»æ•°çš„è®¡ç®—å…¬å¼ï¼Œå½“ä¸¤ä¸ªç”¨æˆ·åªè¯„ä»·äº†ä¸€éƒ¨ç”µå½±æ—¶ï¼Œæ–¹å·®ä¸º0ï¼Œå¯¼è‡´åˆ†æ¯ä¸º0ï¼Œæ— æ³•è®¡ç®—ç›¸å…³ç³»æ•°ã€‚è¿™ç§æƒ…å†µä¸‹ä¼šå‡ºç°"å…±ç°æ€§ä¸è¶³"çš„é—®é¢˜ï¼Œå³åŸºäºæå°‘æ•°å…±åŒè¯„åˆ†è®¡ç®—çš„ç›¸ä¼¼åº¦ä¸å¯é ã€‚è§£å†³æ–¹æ¡ˆæ˜¯è®¾ç½®æœ€å°å…±ç°æ¬¡æ•°é˜ˆå€¼ï¼Œåªæœ‰å½“ä¸¤ä¸ªç”¨æˆ·å…±åŒè¯„ä»·äº†è¶³å¤Ÿå¤šçš„ç‰©å“æ—¶æ‰è®¡ç®—ç›¸ä¼¼åº¦ã€‚
   **Answer:** According to the Pearson correlation coefficient formula, when two users have only rated one movie, the variance is 0, leading to a denominator of 0, making it impossible to calculate the correlation coefficient. In this case, there will be a "co-occurrence insufficiency" problem, meaning similarity calculated based on very few common ratings is unreliable. The solution is to set a minimum co-occurrence threshold, only calculating similarity when two users have jointly rated a sufficient number of items.

7. **å¦‚æœç”¨æˆ·ååŒè¿‡æ»¤ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­å“åº”å¤ªæ…¢ï¼Œå¯èƒ½æ˜¯ä»€ä¹ˆåŸå› ï¼Ÿæœ‰å“ªäº›ä¼˜åŒ–æ–¹æ¡ˆï¼Ÿ**
   **If a user-based collaborative filtering system is too slow in practical application, what might be the reasons? What are some optimization solutions?**
   
   **ç­”æ¡ˆï¼š** å“åº”æ…¢çš„ä¸»è¦åŸå› å¯èƒ½æ˜¯ï¼š
   **Answer:** The main reasons for slow response might be:
   - ç”¨æˆ·æ•°é‡å·¨å¤§ï¼Œè®¡ç®—æ‰€æœ‰ç”¨æˆ·å¯¹çš„ç›¸ä¼¼åº¦å¤æ‚åº¦ä¸ºO(nÂ²)
     Large number of users, complexity of calculating similarity for all user pairs is O(nÂ²)
   - æ²¡æœ‰ä½¿ç”¨ç¨€ç–çŸ©é˜µå­˜å‚¨ï¼Œå†…å­˜å ç”¨å¤§
     Not using sparse matrix storage, leading to large memory usage
   - å®æ—¶è®¡ç®—ç›¸ä¼¼åº¦ï¼Œæ²¡æœ‰é¢„è®¡ç®—
     Computing similarity in real-time without pre-computation
   
   ä¼˜åŒ–æ–¹æ¡ˆåŒ…æ‹¬ï¼š
   Optimization solutions include:
   - ä½¿ç”¨è¿‘ä¼¼æœ€è¿‘é‚»ç®—æ³•ï¼ˆå¦‚LSHï¼‰å¿«é€ŸæŸ¥æ‰¾ç›¸ä¼¼ç”¨æˆ·
     Use approximate nearest neighbor algorithms (like LSH) to quickly find similar users
   - é¢„è®¡ç®—å¹¶ç¼“å­˜ç”¨æˆ·ç›¸ä¼¼åº¦çŸ©é˜µ
     Pre-compute and cache user similarity matrix
   - å¯¹çŸ©é˜µè¿›è¡Œé™ç»´å¤„ç†ï¼ˆå¦‚ä½¿ç”¨SVDï¼‰
     Dimensionality reduction of the matrix (e.g., using SVD)
   - é‡‡ç”¨å¢é‡æ›´æ–°ï¼Œåªåœ¨å¿…è¦æ—¶é‡æ–°è®¡ç®—
     Use incremental updates, recalculate only when necessary
   - ä½¿ç”¨åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶å¤„ç†å¤§è§„æ¨¡æ•°æ®
     Use distributed computing frameworks for large-scale data
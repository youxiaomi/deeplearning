import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from collections import defaultdict
import random

class UserBasedCollaborativeFiltering:
    def __init__(self, num_users, num_items, data_path=None):
        """
        åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤æ¨èç³»ç»Ÿ
        User-based collaborative filtering recommendation system
        
        Args:
            num_users: ç”¨æˆ·æ•°é‡ Number of users
            num_items: ç‰©å“æ•°é‡ Number of items
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ Path to data file
        """
        self.num_users = num_users
        self.num_items = num_items
        self.data_path = data_path
        self.rating_matrix = None  # ç”¨æˆ·-ç‰©å“è¯„åˆ†çŸ©é˜µ User-item rating matrix
        self.user_similarity = None  # ç”¨æˆ·ç›¸ä¼¼åº¦çŸ©é˜µ User similarity matrix
        self.user_mean = None  # ç”¨æˆ·å¹³å‡è¯„åˆ† User mean rating
        
    def generate_sample_data(self, num_ratings=1000, sparsity_rate=0.95):
        """
        ç”Ÿæˆæ¨¡æ‹Ÿç”¨æˆ·è¯„åˆ†æ•°æ®
        Generate synthetic user rating data
        
        Args:
            num_ratings: æ€»è¯„åˆ†æ•°é‡ Total number of ratings
            sparsity_rate: ç¨€ç–ç‡ï¼Œ0.95è¡¨ç¤º95%çš„å•å…ƒæ ¼ä¸ºç©º
                           Sparsity rate, 0.95 means 95% of cells are empty
        """
        print("ğŸ”„ æ­£åœ¨ç”Ÿæˆæ¨¡æ‹Ÿè¯„åˆ†æ•°æ®...")
        print("ğŸ”„ Generating synthetic rating data...")
        
        # åˆå§‹åŒ–è¯„åˆ†çŸ©é˜µ
        # Initialize rating matrix
        self.rating_matrix = np.zeros((self.num_users, self.num_items))
        
        # ç”Ÿæˆè¯„åˆ†æ•°æ®
        # Generate rating data
        generated = 0
        while generated < num_ratings:
            user_id = random.randint(0, self.num_users - 1)
            item_id = random.randint(0, self.num_items - 1)
            
            # è·³è¿‡å·²å­˜åœ¨çš„è¯„åˆ†
            # Skip existing ratings
            if self.rating_matrix[user_id, item_id] != 0:
                continue
                
            # æ¨¡æ‹Ÿç”¨æˆ·è¯„åˆ†è¡Œä¸ºï¼šå¼•å…¥ç”¨æˆ·åå¥½å’Œç‰©å“å—æ¬¢è¿ç¨‹åº¦
            # Simulate user rating behavior: introduce user preference and item popularity
            user_bias = np.random.normal(0, 0.5)  # ç”¨æˆ·è¯„åˆ†åè§ User rating bias
            item_popularity = np.random.normal(3.5, 1.0)  # ç‰©å“åŸºç¡€å¾—åˆ† Item base score
            
            # è¯„åˆ† = ç‰©å“å—æ¬¢è¿ç¨‹åº¦ + ç”¨æˆ·åè§ + å™ªå£°
            # Rating = Item popularity + User bias + Noise
            rating = item_popularity + user_bias + np.random.normal(0, 0.3)
            rating = np.clip(rating, 1, 5)  # é™åˆ¶åœ¨1-5åˆ†ä¹‹é—´ Constrain to 1-5 range
            rating = round(rating * 2) / 2  # å››èˆäº”å…¥åˆ°0.5çš„å€æ•° Round to nearest 0.5
            
            self.rating_matrix[user_id, item_id] = rating
            generated += 1
            
        print(f"âœ… æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå®Œæˆï¼å…±{generated}æ¡è¯„åˆ†è®°å½•");
        print(f"âœ… Data generation completed! {generated} rating records generated")
        print(f"ğŸ”‹ çŸ©é˜µå¯†åº¦: {(generated/(self.num_users*self.num_items)):.2%}")
        print(f"ğŸ”‹ Matrix density: {(generated/(self.num_users*self.num_items)):.2%}")
        
        return self.rating_matrix
    
    def load_data(self):
        """
        ä»æ–‡ä»¶åŠ è½½æ•°æ®
        Load data from file
        """
        if self.data_path is None:
            raise ValueError("æ•°æ®è·¯å¾„æœªæŒ‡å®šï¼Data path not specified!")
            
        try:
            df = pd.read_csv(self.data_path)
            self.rating_matrix = np.zeros((self.num_users, self.num_items))
            
            for _, row in df.iterrows():
                user_id = int(row['user_id'])
                item_id = int(row['item_id'])
                rating = float(row['rating'])
                self.rating_matrix[user_id, item_id] = rating
                
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼æˆåŠŸåŠ è½½{len(df)}æ¡è®°å½•")
            print(f"âœ… Data loaded successfully! {len(df)} records loaded")
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            print(f"âŒ Data loading failed: {e}")
            # å¤±è´¥æ—¶ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            # Generate synthetic data on failure
            self.generate_sample_data()
            
        return self.rating_matrix
    
    def preprocess_data(self):
        """
        æ•°æ®é¢„å¤„ç†ï¼šè®¡ç®—ç”¨æˆ·å¹³å‡åˆ†ï¼Œå¤„ç†ç¼ºå¤±å€¼
        Data preprocessing: calculate user mean, handle missing values
        """
        print("ğŸ§¹ å¼€å§‹æ•°æ®é¢„å¤„ç†...")
        print("ğŸ§¹ Starting data preprocessing...")
        
        # è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„å¹³å‡è¯„åˆ†ï¼ˆä»…è€ƒè™‘éé›¶è¯„åˆ†ï¼‰
        # Calculate mean rating for each user (only non-zero ratings)
        self.user_mean = np.zeros(self.num_users)
        for user_id in range(self.num_users):
            user_ratings = self.rating_matrix[user_id][self.rating_matrix[user_id] != 0]
            if len(user_ratings) > 0:
                self.user_mean[user_id] = np.mean(user_ratings)
            else:
                self.user_mean[user_id] = 3.0  # é»˜è®¤å¹³å‡åˆ† Default mean rating
        
        print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼è®¡ç®—äº†ç”¨æˆ·å¹³å‡åˆ†")
        print("âœ… Data preprocessing completed! Calculated user mean ratings")
        
        return self.rating_matrix, self.user_mean
    
    def calculate_similarity(self, method='cosine'):
        """
        è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦çŸ©é˜µ
        Calculate user similarity matrix
        
        Args:
            method: ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³• 'cosine' æˆ– 'pearson'
                    Similarity method: 'cosine' or 'pearson'
        """
        print(f"ğŸ” ä½¿ç”¨{method}æ–¹æ³•è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦...")
        print(f"ğŸ” Calculating user similarity using {method} method...")
        
        # åˆ›å»ºç”¨äºè®¡ç®—ç›¸ä¼¼åº¦çš„çŸ©é˜µ
        # Create matrix for similarity calculation
        if method == 'pearson':
            # çš®å°”é€Šç›¸å…³ç³»æ•°éœ€è¦ä¸­å¿ƒåŒ–å¤„ç†
            # Pearson correlation requires centering
            similarity_matrix = np.zeros((self.num_users, self.num_users))
            
            for i in range(self.num_users):
                for j in range(i, self.num_users):  # åªè®¡ç®—ä¸Šä¸‰è§’çŸ©é˜µ
                    if i == j:
                        similarity_matrix[i, j] = 1.0
                    else:
                        # æ‰¾åˆ°ä¸¤ä¸ªç”¨æˆ·éƒ½è¯„è¿‡åˆ†çš„ç‰©å“
                        # Find items rated by both users
                        common_items = ((self.rating_matrix[i] != 0) & 
                                      (self.rating_matrix[j] != 0))
                        
                        if np.sum(common_items) < 2:  # è‡³å°‘éœ€è¦2ä¸ªå…±åŒè¯„åˆ†
                            similarity_matrix[i, j] = 0.0
                            similarity_matrix[j, i] = 0.0
                        else:
                            # æå–å…±åŒè¯„åˆ†
                            # Extract common ratings
                            ratings_i = self.rating_matrix[i][common_items]
                            ratings_j = self.rating_matrix[j][common_items]
                            
                            # ä¸­å¿ƒåŒ–å¤„ç†
                            # Centering
                            ratings_i_centered = ratings_i - np.mean(ratings_i)
                            ratings_j_centered = ratings_j - np.mean(ratings_j)
                            
                            # è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
                            # Calculate Pearson correlation
                            numerator = np.sum(ratings_i_centered * ratings_j_centered)
                            denominator = (np.sqrt(np.sum(ratings_i_centered**2)) * 
                                         np.sqrt(np.sum(ratings_j_centered**2)))
                            
                            if denominator == 0:
                                sim = 0.0
                            else:
                                sim = numerator / denominator
                                
                            similarity_matrix[i, j] = sim
                            similarity_matrix[j, i] = sim
        
        elif method == 'cosine':
            # ä½™å¼¦ç›¸ä¼¼åº¦
            # Cosine similarity
            similarity_matrix = cosine_similarity(self.rating_matrix)
            
        self.user_similarity = similarity_matrix
        print("âœ… ç›¸ä¼¼åº¦è®¡ç®—å®Œæˆï¼")
        print("âœ… Similarity calculation completed!")
        
        return self.user_similarity
    
    def predict_rating(self, user_id, item_id, k=20):
        """
        é¢„æµ‹ç”¨æˆ·å¯¹ç‰©å“çš„è¯„åˆ†
        Predict user's rating for an item
        
        Args:
            user_id: ç”¨æˆ·ID User ID
            item_id: ç‰©å“ID Item ID
            k: ä½¿ç”¨å¤šå°‘ä¸ªæœ€ç›¸ä¼¼çš„ç”¨æˆ· Use how many most similar users
        """
        # æ‰¾åˆ°ç›®æ ‡ç”¨æˆ·å·²ç»è¯„åˆ†çš„ç‰©å“
        # Find items already rated by target user
        user_rated_items = self.rating_matrix[user_id] != 0
        
        # è®¡ç®—å…¶ä»–ç”¨æˆ·ä¸ç›®æ ‡ç”¨æˆ·çš„ç›¸ä¼¼åº¦
        # Calculate similarity between other users and target user
        similarities = self.user_similarity[user_id]
        
        # æ‰¾åˆ°ä¸ç›®æ ‡ç”¨æˆ·æœ‰å…±åŒè¯„åˆ†ç‰©å“çš„ç”¨æˆ·
        # Find users who have common rated items with target user
        potential_neighbors = []
        for other_user_id in range(self.num_users):
            if other_user_id == user_id:
                continue
                
            # æ£€æŸ¥æ˜¯å¦æœ‰å…±åŒè¯„åˆ†çš„ç‰©å“
            # Check if there are common rated items
            other_rated_items = self.rating_matrix[other_user_id] != 0
            if np.sum(user_rated_items & other_rated_items) > 0:  # è‡³å°‘æœ‰ä¸€ä¸ªå…±åŒè¯„åˆ†
                potential_neighbors.append(other_user_id)
        
        if len(potential_neighbors) == 0:
            # æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·ï¼Œè¿”å›ç”¨æˆ·å¹³å‡åˆ†
            # No similar users found, return user's mean rating
            return self.user_mean[user_id]
        
        # ä»æ½œåœ¨é‚»å±…ä¸­é€‰æ‹©æœ€ç›¸ä¼¼çš„kä¸ªç”¨æˆ·
        # Select top-k most similar users from potential neighbors
        neighbor_similarities = [(sim, uid) for uid, sim in enumerate(similarities) 
                               if uid in potential_neighbors]
        neighbor_similarities.sort(reverse=True)  # ä»é«˜åˆ°ä½æ’åº
        top_neighbors = neighbor_similarities[:k]
        
        if len(top_neighbors) == 0 or top_neighbors[0][0] <= 0:
            # æ²¡æœ‰æ­£ç›¸ä¼¼åº¦çš„é‚»å±…ï¼Œè¿”å›ç”¨æˆ·å¹³å‡åˆ†
            # No neighbors with positive similarity, return user's mean rating
            return self.user_mean[user_id]
        
        # è®¡ç®—åŠ æƒé¢„æµ‹è¯„åˆ†
        # Calculate weighted predicted rating
        numerator = 0.0
        denominator = 0.0
        
        for similarity, neighbor_id in top_neighbors:
            # æ£€æŸ¥é‚»å±…æ˜¯å¦è¯„ä»·è¿‡è¯¥ç‰©å“
            # Check if neighbor has rated this item
            if self.rating_matrix[neighbor_id, item_id] == 0:
                continue
                
            # é‚»å±…çš„è¯„åˆ†åå·®
            # Neighbor's rating deviation
            neighbor_deviation = self.rating_matrix[neighbor_id, item_id] - self.user_mean[neighbor_id]
            
            numerator += similarity * neighbor_deviation
            denominator += abs(similarity)  # ä½¿ç”¨ç»å¯¹å€¼é¿å…è´Ÿå€¼æŠµæ¶ˆ
                                  # Use absolute value to prevent negative cancellation

        if denominator == 0:
            return self.user_mean[user_id]
        
        # æœ€ç»ˆé¢„æµ‹è¯„åˆ† = ç”¨æˆ·å¹³å‡åˆ† + åŠ æƒåå·®
        # Final predicted rating = user mean + weighted deviation
        predicted_rating = self.user_mean[user_id] + (numerator / denominator)
        predicted_rating = np.clip(predicted_rating, 1, 5)  # é™åˆ¶åœ¨1-5åˆ†ä¹‹é—´
                                             # Constrain to 1-5 range
        
        return predicted_rating
    
    def evaluate(self, test_data, k=20):
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        Evaluate model performance
        
        Args:
            test_data: æµ‹è¯•æ•°æ® [(user_id, item_id, true_rating), ...]
                       Test data [(user_id, item_id, true_rating), ...]
            k: ä½¿ç”¨çš„é‚»å±…æ•°é‡ Number of neighbors used
        """
        predictions = []
        true_ratings = []
        
        print(f"ğŸ“Š æ­£åœ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œä½¿ç”¨k={k}ä¸ªé‚»å±…...")
        print(f"ğŸ“Š Evaluating model performance, using k={k} neighbors...")
        
        for user_id, item_id, true_rating in test_data:
            pred_rating = self.predict_rating(user_id, item_id, k)
            predictions.append(pred_rating)
            true_ratings.append(true_rating)
        
        # è®¡ç®—RMSEå’ŒMAE
        # Calculate RMSE and MAE
        predictions = np.array(predictions)
        true_ratings = np.array(true_ratings)
        
        rmse = np.sqrt(np.mean((predictions - true_ratings) ** 2))
        mae = np.mean(np.abs(predictions - true_ratings))
        
        print(f"ğŸ“ˆ è¯„ä¼°ç»“æœï¼š")
        print(f"ğŸ“ˆ Evaluation results:")
        print(f"   RMSE: {rmse:.4f}")
        print(f"   MAE:  {mae:.4f}")
        
        return rmse, mae
    
    def get_top_n_recommendations(self, user_id, n=10, k=20):
        """
        ä¸ºç”¨æˆ·ç”ŸæˆTop-Næ¨è
        Generate Top-N recommendations for user
        
        Args:
            user_id: ç”¨æˆ·ID User ID
            n: æ¨èæ•°é‡ Number of recommendations
            k: ä½¿ç”¨çš„é‚»å±…æ•°é‡ Number of neighbors used
        """
        print(f"ğŸ¯ ä¸ºç”¨æˆ·{user_id}ç”ŸæˆTop-{n}æ¨è...")
        print(f"ğŸ¯ Generating Top-{n} recommendations for user {user_id}...")
        
        # æ‰¾å‡ºç”¨æˆ·æœªè¯„åˆ†çš„ç‰©å“
        # Find items not rated by user
        user_rated = self.rating_matrix[user_id] != 0
        unrated_items = np.where(~user_rated)[0]
        
        if len(unrated_items) == 0:
            print("âŒ ç”¨æˆ·å·²ç»è¯„è¿‡æ‰€æœ‰ç‰©å“ï¼Œæ— æ³•æ¨è")
            print("âŒ User has rated all items, cannot recommend")
            return []
        
        # é¢„æµ‹æ‰€æœ‰æœªè¯„åˆ†ç‰©å“çš„è¯„åˆ†
        # Predict ratings for all unrated items
        item_predictions = []
        for item_id in unrated_items:
            pred_rating = self.predict_rating(user_id, item_id, k)
            item_predictions.append((item_id, pred_rating))
        
        # æŒ‰é¢„æµ‹è¯„åˆ†æ’åº
        # Sort by predicted rating
        item_predictions.sort(key=lambda x: x[1], reverse=True)
        
        # è¿”å›Top-N
        # Return Top-N
        top_n = item_predictions[:n]
        
        print(f"âœ… Top-{n}æ¨èç”Ÿæˆå®Œæˆï¼")
        print("âœ… Top-N recommendations generated!")
        
        return top_n

# ===================== ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯• =====================
# ===================== Usage Example and Testing =====================

def main():
    """
    ä¸»å‡½æ•°ï¼šæ¼”ç¤ºç”¨æˆ·ååŒè¿‡æ»¤ç³»ç»Ÿçš„å·¥ä½œæµç¨‹
    Main function: demonstrate the workflow of user-based collaborative filtering system
    """
    print("ğŸš€ å¼€å§‹æ¼”ç¤ºåŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤æ¨èç³»ç»Ÿ")
    print("ğŸš€ Starting demonstration of user-based collaborative filtering recommendation system")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ–ç³»ç»Ÿ
    # 1. Initialize system
    NUM_USERS = 100
    NUM_ITEMS = 50
    recommender = UserBasedCollaborativeFiltering(NUM_USERS, NUM_ITEMS)
    
    # 2. ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    # 2. Generate synthetic data
    data = recommender.generate_sample_data(num_ratings=800)
    
    # 3. æ•°æ®é¢„å¤„ç†
    # 3. Data preprocessing
    rating_matrix, user_mean = recommender.preprocess_data()
    
    # 4. è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦
    # 4. Calculate user similarity
    similarity_matrix = recommender.calculate_similarity(method='pearson')
    
    # 5. æ¨¡å‹è¯„ä¼°
    # 5. Model evaluation
    # åˆ›å»ºæµ‹è¯•é›†ï¼šéšæœºé€‰æ‹©ä¸€äº›å·²æœ‰çš„è¯„åˆ†ä½œä¸ºæµ‹è¯•
    # Create test set: randomly select some existing ratings as test
    test_data = []
    for _ in range(100):
        user_id = random.randint(0, NUM_USERS - 1)
        item_id = random.randint(0, NUM_ITEMS - 1)
        if rating_matrix[user_id, item_id] != 0:  # ç¡®ä¿è¯¥è¯„åˆ†å­˜åœ¨
            test_data.append((user_id, item_id, rating_matrix[user_id, item_id]))
    
    rmse, mae = recommender.evaluate(test_data, k=20)
    
    # 6
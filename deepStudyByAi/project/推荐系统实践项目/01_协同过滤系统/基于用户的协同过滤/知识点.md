# åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤ | User-based Collaborative Filtering

## ğŸŒŸ æ ¸å¿ƒæ€æƒ³ | Core Idea

**ä½ ä¸æ˜¯ä¸€ä¸ªäººåœ¨æˆ˜æ–—ï¼ç³»ç»Ÿä¼šæ‰¾åˆ°å’Œä½ å“å‘³ç›¸ä¼¼çš„ç”¨æˆ·ç¾¤ä½“ï¼Œå€Ÿé‰´ä»–ä»¬çš„é€‰æ‹©æ¥ä¸ºä½ æ¨èã€‚**
**You're not alone! The system will find user groups with similar tastes to you and recommend based on their choices.**

è¿™å°±åƒä½ å»ç«é”…åº—ï¼ŒæœåŠ¡å‘˜é—®ï¼š"å…ˆç”Ÿï¼Œæœ‰ä¸€ä½å’Œæ‚¨ä¸€æ ·å–œæ¬¢éº»è¾£å£å‘³çš„é¡¾å®¢åˆšåˆšç‚¹äº†ä¸€ä»½æ¯›è‚šï¼Œè¦ä¸è¦è¯•è¯•ï¼Ÿ"è¿™ç§åŸºäºç›¸ä¼¼ç”¨æˆ·åå¥½çš„æ¨èå°±æ˜¯ç”¨æˆ·ååŒè¿‡æ»¤ã€‚
It's like when you go to a hotpot restaurant, and the server asks: "Sir, a customer with the same spicy preference as you just ordered tripe, would you like to try it?" This kind of recommendation based on similar user preferences is user-based collaborative filtering.

## ğŸ§© ç®—æ³•æµç¨‹ | Algorithm Workflow

### 1. æ•°æ®æ”¶é›†é˜¶æ®µ | Data Collection Phase

ç³»ç»Ÿé¦–å…ˆéœ€è¦æ”¶é›†ç”¨æˆ·çš„è¡Œä¸ºæ•°æ®ï¼š
The system first needs to collect user behavior data:

- **æ˜¾å¼åé¦ˆ**ï¼šç”¨æˆ·ç›´æ¥ç»™å‡ºçš„è¯„åˆ†ã€ç‚¹èµã€æ”¶è—ç­‰
  **Explicit feedback**: Ratings, likes, collections directly given by users
- **éšå¼åé¦ˆ**ï¼šç”¨æˆ·çš„æµè§ˆæ—¶é•¿ã€è´­ä¹°è®°å½•ã€åŠ å…¥è´­ç‰©è½¦ç­‰
  **Implicit feedback**: User's browsing duration, purchase history, adding to cart, etc.

**ç”Ÿæ´»ä¾‹å­**ï¼š
**Life example:**
- åœ¨ç”µå•†ç½‘ç«™ï¼Œä½ ç»™å•†å“æ‰“äº†5æ˜Ÿæ˜¯æ˜¾å¼åé¦ˆ
  On e-commerce websites, giving a product 5 stars is explicit feedback
- ä½ åœ¨å•†å“é¡µé¢åœç•™äº†5åˆ†é’Ÿæ˜¯éšå¼åé¦ˆ
  Staying on a product page for 5 minutes is implicit feedback

### 2. ç›¸ä¼¼åº¦è®¡ç®—é˜¶æ®µ | Similarity Calculation Phase

**æŠŠç”¨æˆ·å˜æˆå‘é‡ï¼Œç”¨æ•°å­¦æ–¹æ³•è¡¡é‡ç›¸ä¼¼åº¦**
**Turn users into vectors and use mathematical methods to measure similarity**

æ¯ä¸ªç”¨æˆ·éƒ½å¯ä»¥è¡¨ç¤ºä¸ºä¸€ä¸ªå‘é‡ï¼Œå‘é‡çš„æ¯ä¸ªç»´åº¦ä»£è¡¨å¯¹æŸä¸ªç‰©å“çš„è¯„åˆ†ã€‚ç„¶åä½¿ç”¨ç›¸ä¼¼åº¦åº¦é‡æ–¹æ³•ï¼š
Each user can be represented as a vector, with each dimension representing the rating for a particular item. Then use similarity measurement methods:

| ç›¸ä¼¼åº¦æ–¹æ³• | å…¬å¼ | é€‚ç”¨åœºæ™¯ |
| --- | --- | --- |
| **ä½™å¼¦ç›¸ä¼¼åº¦** | $\frac{\vec{A} \cdot \vec{B}}{\|\vec{A}\| \|\vec{B}\|}$ | é€‚åˆç¨€ç–æ•°æ®ï¼Œå…³æ³¨è¯„åˆ†æ–¹å‘ |
| **çš®å°”é€Šç›¸å…³ç³»æ•°** | $\frac{\sum (A_i-\bar{A})(B_i-\bar{B})}{\sqrt{\sum (A_i-\bar{A})^2}\sqrt{\sum (B_i-\bar{B})^2}}$ | æ¶ˆé™¤ç”¨æˆ·è¯„åˆ†åè§ï¼Œæ›´å‡†ç¡® |
| **æ¬§æ°è·ç¦»** | $\sqrt{\sum (A_i-B_i)^2}$ | é€‚åˆå¯†é›†æ•°æ®ï¼Œå…³æ³¨ç»å¯¹å·®å¼‚ |

**é€‰æ‹©å»ºè®®**ï¼š
**Selection advice:**
- æ•°æ®ç¨€ç–æ—¶ä¼˜å…ˆé€‰æ‹©**ä½™å¼¦ç›¸ä¼¼åº¦**
  Prefer **cosine similarity** when data is sparse
- éœ€è¦æ¶ˆé™¤ç”¨æˆ·è¯„åˆ†ä¹ æƒ¯å½±å“æ—¶é€‰æ‹©**çš®å°”é€Šç›¸å…³ç³»æ•°**
  Choose **pearson correlation coefficient** when need to eliminate user rating habit influence

### 3. é‚»å±…é€‰æ‹©é˜¶æ®µ | Neighbor Selection Phase

ä¸æ˜¯æ‰€æœ‰ç”¨æˆ·éƒ½è¦è€ƒè™‘ï¼Œåªé€‰æ‹©æœ€ç›¸ä¼¼çš„Kä¸ªç”¨æˆ·ä½œä¸º"é‚»å±…"ï¼š
Not all users need to be considered, only the K most similar users are selected as "neighbors":

- **Kå€¼é€‰æ‹©**ï¼šé€šå¸¸Kåœ¨20-50ä¹‹é—´
  **K selection**: K is usually between 20-50
- **ç›¸ä¼¼åº¦é˜ˆå€¼**ï¼šåªé€‰æ‹©ç›¸ä¼¼åº¦å¤§äºæŸä¸ªé˜ˆå€¼çš„ç”¨æˆ·
  **Similarity threshold**: Only select users with similarity above a certain threshold

**è°ƒå‚æŠ€å·§**ï¼š
**Parameter tuning tips:**
- Kå¤ªå°ï¼šæ¨èå¤šæ ·æ€§ä¸è¶³
  K too small: Lack of recommendation diversity
- Kå¤ªå¤§ï¼šè®¡ç®—é‡å¤§ï¼Œå¯èƒ½åŒ…å«ä¸ç›¸å…³çš„ç”¨æˆ·
  K too large: High computational cost, may include irrelevant users

### 4. è¯„åˆ†é¢„æµ‹é˜¶æ®µ | Rating Prediction Phase

ç»¼åˆé‚»å±…ä»¬çš„è¯„åˆ†æ¥é¢„æµ‹ç›®æ ‡ç”¨æˆ·å¯¹æœªæ¥è§¦ç‰©å“çš„è¯„åˆ†ï¼š
Synthesize neighbors' ratings to predict the target user's rating for unseen items:

$$\hat{r}_{ui} = \bar{r}_u + \frac{\sum_{v \in N(u)} \text{sim}(u,v) \times (r_{vi} - \bar{r}_v)}{\sum_{v \in N(u)} |\text{sim}(u,v)|}$$

**å…¬å¼è§£è¯»**ï¼š
**Formula interpretation:**
1. $\bar{r}_u$ï¼šä½ è‡ªå·±çš„å¹³å‡è¯„åˆ† Your own average rating
2. $r_{vi} - \bar{r}_v$ï¼šé‚»å±…vå¯¹ç‰©å“içš„è¯„åˆ†ä¸å…¶å¹³å‡åˆ†çš„åå·®
   Neighbor v's rating for item i minus their average rating
3. åŠ æƒå¹³å‡ï¼šç›¸ä¼¼åº¦è¶Šé«˜ï¼Œé‚»å±…çš„æŠ•ç¥¨æƒè¶Šé‡
   Weighted average: The higher the similarity, the heavier the neighbor's vote

## ğŸš€ ç®—æ³•ä¼˜ç¼ºç‚¹ | Advantages and Disadvantages

### ä¼˜ç‚¹ | Advantages

âœ… **æ— éœ€ç‰©å“ç‰¹å¾**ï¼šä¸éœ€è¦äº†è§£ç‰©å“çš„å…·ä½“å†…å®¹ï¼Œåªçœ‹ç”¨æˆ·è¡Œä¸º
   **No item features needed**: No need to understand item content, only user behavior

âœ… **å‘ç°æ–°å…´è¶£**ï¼šå¯ä»¥æ¨èç”¨æˆ·ä»æœªæ¥è§¦è¿‡çš„å“ç±»
   **Discover new interests**: Can recommend categories the user has never encountered

âœ… **åŸç†ç›´è§‚**ï¼š"ç‰©ä»¥ç±»èšï¼Œäººä»¥ç¾¤åˆ†"çš„è‡ªç„¶å»¶ä¼¸
   **Intuitive principle**: Natural extension of "birds of a feather flock together"

### ç¼ºç‚¹ | Disadvantages

âŒ **å†·å¯åŠ¨é—®é¢˜**ï¼šæ–°ç”¨æˆ·æ²¡æœ‰è¡Œä¸ºæ•°æ®ï¼Œæ— æ³•æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·
   **Cold start problem**: New users have no behavior data, cannot find similar users

âŒ **ç¨€ç–æ€§é—®é¢˜**ï¼šç”¨æˆ·åªè¯„ä»·äº†æå°‘æ•°ç‰©å“ï¼Œéš¾ä»¥å‡†ç¡®è®¡ç®—ç›¸ä¼¼åº¦
   **Sparsity problem**: Users only rate a very small number of items, making it difficult to accurately calculate similarity

âŒ **å¯æ‰©å±•æ€§å·®**ï¼šç”¨æˆ·é‡å¾ˆå¤§æ—¶ï¼Œè®¡ç®—æ‰€æœ‰ç”¨æˆ·ç›¸ä¼¼åº¦éå¸¸è€—æ—¶
   **Poor scalability**: When there are many users, calculating similarity between all users is very time-consuming

## ğŸ’¡ å®é™…åº”ç”¨æŠ€å·§ | Practical Application Tips

### æ•°æ®é¢„å¤„ç† | Data Preprocessing

**1. çŸ©é˜µç¨€ç–æ€§å¤„ç†**
**1. Matrix sparsity handling**

ç°å®ä¸­çš„ç”¨æˆ·-ç‰©å“è¯„åˆ†çŸ©é˜µé€šå¸¸éå¸¸ç¨€ç–ï¼ˆè¶…è¿‡95%æ˜¯ç©ºç™½ï¼‰ï¼š
In reality, user-item rating matrices are usually very sparse (over 95% are blank):

```python
# æ£€æŸ¥çŸ©é˜µç¨€ç–æ€§
# Check matrix sparsity
sparsity = 1.0 - len(ratings) / (num_users * num_items)
print(f"Matrix sparsity: {sparsity:.2%}")
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
**Solutions:**
- ä½¿ç”¨ç¨€ç–çŸ©é˜µå­˜å‚¨
  Use sparse matrix storage
- é‡‡ç”¨è¿‘ä¼¼æœ€è¿‘é‚»ç®—æ³•
  Use approximate nearest neighbor algorithms

### æ•ˆç‡ä¼˜åŒ– | Efficiency Optimization

**1. å±€éƒ¨æ•æ„Ÿå“ˆå¸Œ(LSH)**
**1. Locality Sensitive Hashing (LSH)**

å¿«é€Ÿæ‰¾åˆ°å¯èƒ½ç›¸ä¼¼çš„ç”¨æˆ·ï¼Œé¿å…è®¡ç®—æ‰€æœ‰ç”¨æˆ·å¯¹çš„ç›¸ä¼¼åº¦ï¼š
Quickly find potentially similar users, avoiding calculating similarity for all user pairs:

```python
from sklearn.neighbors import LSHForest

# ä½¿ç”¨LSHå¿«é€ŸæŸ¥æ‰¾è¿‘ä¼¼æœ€è¿‘é‚»
# Use LSH to quickly find approximate nearest neighbors
lshf = LSHForest(n_estimators=10, n_candidates=100)
lshf.fit(train_matrix)

# æŸ¥è¯¢æœ€ç›¸ä¼¼çš„ç”¨æˆ·
# Query most similar users
distances, indices = lshf.kneighbors(train_matrix[query_user], n_neighbors=20)
```

**2. åœ¨çº¿æ›´æ–°**
**2. Online updating**

ç”¨æˆ·æœ‰äº†æ–°è¡Œä¸ºåï¼Œä¸éœ€è¦é‡æ–°è®¡ç®—æ‰€æœ‰ç›¸ä¼¼åº¦ï¼š
After a user has new behavior, no need to recalculate all similarities:

- åªæ›´æ–°å—å½±å“ç”¨æˆ·çš„ç›¸ä¼¼åº¦
  Only update similarities of affected users
- ä½¿ç”¨å¢é‡è®¡ç®—æ–¹æ³•
  Use incremental calculation methods

## ğŸŒ ç°ä»£å‘å±• | Modern Developments

### æ··åˆæ¨èç³»ç»Ÿ | Hybrid Recommender Systems

å°†ç”¨æˆ·ååŒè¿‡æ»¤ä¸å…¶ä»–æ–¹æ³•ç»“åˆï¼š
Combining user-based collaborative filtering with other methods:

1. **ä¸å†…å®¹æ¨èç»“åˆ**ï¼šç”¨å†…å®¹ç‰¹å¾è¾…åŠ©è§£å†³å†·å¯åŠ¨é—®é¢˜
   **With content-based recommendation**: Use content features to help solve cold start problem

2. **ä¸çŸ©é˜µåˆ†è§£ç»“åˆ**ï¼šç”¨SVDç­‰æ–¹æ³•é™ç»´åå†è®¡ç®—ç›¸ä¼¼åº¦
   **With matrix factorization**: Use SVD and other methods for dimensionality reduction before calculating similarity

3. **ä¸æ·±åº¦å­¦ä¹ ç»“åˆ**ï¼šç”¨ç¥ç»ç½‘ç»œå­¦ä¹ ç”¨æˆ·å’Œç‰©å“çš„åµŒå…¥è¡¨ç¤º
   **With deep learning**: Use neural networks to learn embedding representations of users and items

ç”¨æˆ·ååŒè¿‡æ»¤è™½ç„¶ç®€å•ï¼Œä½†å…¶"ä»¥äººä¸ºæœ¬"çš„æ€æƒ³åœ¨ç°ä»£æ¨èç³»ç»Ÿä¸­ä»ç„¶å‘æŒ¥ç€é‡è¦ä½œç”¨ï¼
Although simple, user-based collaborative filtering's "people-centered" philosophy still plays an important role in modern recommender systems!